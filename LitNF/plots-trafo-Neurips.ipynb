{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148e9d34-e26d-4a67-acf8-48081ff27e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thx max\n",
      "good boy\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from jetnet_dataloader import JetNetDataloader\n",
    "from lit_nf import TransGan\n",
    "from plotting import *\n",
    "import pandas as pd\n",
    "from jetnet.evaluation import w1p, w1efp, w1m, cov_mmd,fpnd\n",
    "from jetnet.datasets import JetNet\n",
    "from main import train\n",
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import torch\n",
    "import numpy as np\n",
    "import hist\n",
    "from hist import Hist\n",
    "import traceback\n",
    "from helpers import mass\n",
    "import pandas as pd\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "class plotting_paper():\n",
    "    '''This is a class that takes care of  plotting steps in the script,\n",
    "        It is initialized with the following arguments:\n",
    "        true=the simulated data, note that it needs to be scaled\n",
    "        gen= Generated data , needs to be scaled\n",
    "        step=The current step of the training, this is need for tensorboard\n",
    "        model=the model that is trained, a bit of an overkill as it is only used to access the losses\n",
    "        config=the config used for training\n",
    "        logger=The logger used for tensorboard logging'''\n",
    "    def __init__(self,true,gen,config,step,p,model=None,logger=None,weight=1):\n",
    "        self.config=model.config\n",
    "        self.n_dim=self.config[\"n_dim\"]\n",
    "        self.gen=gen\n",
    "        self.test_set=true\n",
    "        self.step=step\n",
    "        self.model=model\n",
    "        self.p=p\n",
    "\n",
    "        self.weight=weight\n",
    "        if logger is not None:\n",
    "            self.summary=logger\n",
    "    def plot_mass_only(self,m,m_t,bins=15):\n",
    "        fig,ax=plt.subplots(2,1,gridspec_kw={'height_ratios': [3, 1]},figsize=(6,8))\n",
    "        a=min(np.quantile(m_t,0.001),np.quantile(m,0.001))\n",
    "        b=max(np.quantile(m_t,0.999),np.quantile(m,0.999))\n",
    "        a=np.quantile(m_t,0.001)\n",
    "        b=np.quantile(m_t,0.999)\n",
    "        h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "        h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "        bins = h.axes[0].edges\n",
    "        h.fill(m)#,weight=1/self.weight)\n",
    "        h2.fill(m_t)\n",
    "            \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "\n",
    "        main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "            h2,\n",
    "            ax_dict={\"main_ax\":ax[0],\"ratio_ax\":ax[1]},\n",
    "            rp_ylabel=r\"Ratio\",\n",
    "            rp_num_label=\"Flow Generated\",\n",
    "            rp_denom_label=\"MC Simulatied\",\n",
    "            rp_uncert_draw_type=\"line\",  # line or bar\n",
    "        )\n",
    "        ax[0].set_xlabel(\"\")\n",
    "#                 if quantile and v==\"m\" and plot_vline:\n",
    "#                     ax[0,k].hist(m[m_t<np.quantile(m_t,0.1)],histtype='step',bins=bins,alpha=1,color=\"red\",label=\"10% quantile gen\",hatch=\"/\")\n",
    "#                     ax[0,k].vlines(np.quantile(m_t,0.1),0,np.max(h[:]),color=\"red\",label='10% quantile train')\n",
    "\n",
    "        ax[1].set_ylim(0.25,2)\n",
    "        ax[0].set_xlim(a,b)\n",
    "        ax[1].set_xlabel(\"$m_T$\",fontweight=\"bold\")\n",
    "        ax[1].set_xlim(a,b)\n",
    "        ax[0].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "        ax[1].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "  \n",
    "     \n",
    "#             print(\"added figure\")\n",
    "#             self.summary.close()\n",
    "\n",
    "        plt.savefig(\"{}_mass\".format(self.p))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_marginals(self,ith=None,save=False,title=None):\n",
    "        #This plots the marginal distribution for simulation and generation\n",
    "        #Note that this is the data the model sees during training as input to model in the NF\n",
    "        #This is the distribution of one of [eta,phi,pt] of one particle of the n particles per jet: for example the pt of the 3rd particle\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        \n",
    "        plt.switch_backend('agg')\n",
    "        name,label=[\"eta\",\"phi\",\"pt\"],['${\\eta}^{rel}_{7}$',\"${\\phi}^{rel}_{7}$\",\"${p_T}^{rel}_{7}$\"]\n",
    "        fig,ax=plt.subplots(2,3,gridspec_kw={'height_ratios': [3, 1]},figsize=(18,6))\n",
    "        particles=range(self.n_dim) if not ith else [3*ith,3*ith+1,3*ith+2]\n",
    "        plt.suptitle(title,fontweight=\"bold\")\n",
    "        k=0\n",
    "        for i in particles:\n",
    "            if ith:\n",
    "                ax_temp=ax[:,k]\n",
    "            else:\n",
    "                fig,ax_temp=plt.subplots(2,1)\n",
    "            a=np.quantile(self.test_set[:,i].numpy(),0)\n",
    "            b=np.quantile(self.test_set[:,i].numpy(),1)\n",
    "\n",
    "            h=hist.Hist(hist.axis.Regular(15,a,b,label=label[i%3],underflow=False,overflow=False))\n",
    "            h2=hist.Hist(hist.axis.Regular(15,a,b,label=label[i%3],underflow=False,overflow=False))\n",
    "            h.fill(self.gen[:,i].numpy())\n",
    "            h2.fill(self.test_set[:,i].numpy())\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0,k] )\n",
    "       \n",
    "            main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "                h2,\n",
    "                ax_dict={\"main_ax\":ax_temp[0],\"ratio_ax\":ax_temp[1]},\n",
    "                rp_ylabel=r\"Ratio\",\n",
    "#                 rp_xlabel=label[i%3],\n",
    "                rp_num_label=\"Flow Generated\",\n",
    "                rp_denom_label=\"MC Simulated\",\n",
    "                rp_uncert_draw_type=\"line\",  # line or bar\n",
    "            )\n",
    "            \n",
    "            \n",
    "            ax_temp[0].set_xlabel(\"\")\n",
    "            ax_temp[1].set_ylim(0.25,2)\n",
    "            ax_temp[0].set_xlim(a,b)\n",
    "            ax_temp[1].set_xlim(a,b)\n",
    "            ax_temp[1].set_xlabel(label[i%3])\n",
    "            ax_temp[0].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "            ax_temp[1].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "            \n",
    "            \n",
    "            #plt.tight_layout(pad=2)\n",
    "            k+=1\n",
    "        if save:\n",
    "            self.summary.add_figure(\"jet{}_{}\".format(i//3+1,name[i%3]),fig,global_step=self.step)\n",
    "            self.summary.close()\n",
    "        else:\n",
    "            plt.savefig(\"{}_7thpart\".format(self.p))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def plot_2d(self,save=False):\n",
    "        #This creates a 2D histogram of the inclusive distribution for all 3 feature combinations\n",
    "        #Inclusive means that is the distribution of pt of all particles per jet and sample\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        data=self.test_set[:,:self.n_dim].reshape(-1,3).numpy()\n",
    "        gen=self.gen[:,:self.n_dim].reshape(-1,3).numpy()\n",
    "        labels=[r\"$\\eta^{rel}$\",r\"$\\phi^{rel}_7$\",r\"$p_T^{rel}$\"]\n",
    "        names=[\"eta\",\"phi\",\"pt\"]\n",
    "        for index in [[0,1],[0,2],[1,2]]:\n",
    "            \n",
    "            fig,ax=plt.subplots(ncols=2,figsize=(16, 8))\n",
    "            _,x,y,_=ax[0].hist2d(data[:,index[0]],data[:,index[1]],bins=30)\n",
    "            #rebin to only take 5% to 95.0% of signal dis\n",
    "            a=np.quantile(x,0.05)\n",
    "            b=np.quantile(x,0.95)\n",
    "            x=np.linspace(a,b,len(x))\n",
    "            a=np.quantile(y,0.05)\n",
    "            b=np.quantile(y,0.95)\n",
    "            y=np.linspace(a,b,len(y))\n",
    "            if index[1]==2:\n",
    "                y=np.abs(y)+0.00001\n",
    "                y = np.logspace(np.log(y[0]),np.log(y[-1]),len(y))\n",
    "            ax[0].hist2d(data[:,index[0]],data[:,index[1]],bins=[x,y])\n",
    "            data[:,index[0]]=np.abs(data[:,index[0]])+0.00001\n",
    "            ax[1].hist2d(gen[:,index[0]],gen[:,index[1]],bins=[x,y])\n",
    "        \n",
    "        \n",
    "            plt.tight_layout(pad=2)\n",
    "            ax[0].set_xlabel( labels[index[0]],fontweight=\"bold\")\n",
    "            ax[0].set_ylabel( labels[index[1]],fontweight=\"bold\")\n",
    "            \n",
    "            ax[0].set_title(\"MC Simulated\")\n",
    "            ax[1].set_xlabel( labels[index[0]],fontweight=\"bold\")\n",
    "            ax[1].set_ylabel( labels[index[1]],fontweight=\"bold\")\n",
    "            \n",
    "            ax[1].set_title(\"Flow Generated\")\n",
    "           \n",
    "            if save:\n",
    "                self.summary.add_figure(\"2d{}-{}\".format(names[index[0]],names[index[1]]),fig,global_step=self.step)\n",
    "                \n",
    "                # self.summary.close()\n",
    "            else:\n",
    "                plt.savefig(\"{}_2dcorr{}{}\".format(self.p,names[index[0]],names[index[0]]))\n",
    "                plt.show()\n",
    "                \n",
    " \n",
    "        \n",
    "    def oversample(self,m,m_t,weight,save=False,quantile=False,bins=15,plot_vline=False,title=\"\"):\n",
    "        #This creates a histogram of the inclusive distributions and calculates the mass of each jet\n",
    "        #and creates a histogram of that\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        #if quantile, this also creates a histogram of a subsample of the generated data, \n",
    "        # where the mass used to condition the flow is in the first 10% percentile of the simulated mass dist\n",
    "        i=0\n",
    "        k=0\n",
    "        fig,ax=plt.subplots(2,4,gridspec_kw={'height_ratios': [3, 1]},figsize=(20,5))\n",
    "        plt.suptitle(title,fontweight=\"bold\")\n",
    "        for v,name in zip([\"eta\",\"phi\",\"pt\",\"m\"],[r\"$\\eta^{rel}$\",r\"$\\phi^{rel}$\",r\"$p_T^{rel}$\",r\"$m^{rel}$\"]):\n",
    "            \n",
    "            if v!=\"m\":\n",
    "                a=min(np.quantile(self.gen[:,i],0.001),np.quantile(self.test_set[:,i],0.001))\n",
    "                b=max(np.quantile(self.gen[:,i],0.999),np.quantile(self.test_set[:,i],0.999))     \n",
    "                \n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h.fill(self.gen[:,i],weight=1/weight)\n",
    "                h2.fill(self.test_set[:,i])\n",
    "                i+=1\n",
    "            else:\n",
    "                a=min(np.quantile(m_t,0.001),np.quantile(m,0.001))\n",
    "                b=max(np.quantile(m_t,0.999),np.quantile(m,0.999))\n",
    "                a=np.quantile(m_t,0.001)\n",
    "                b=np.quantile(m_t,0.999)\n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                bins = h.axes[0].edges\n",
    "                h.fill(m,weight=1/weight)#,weight=1/self.weight)\n",
    "                h2.fill(m_t)\n",
    "            \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            try:\n",
    "                main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "                    h2,\n",
    "                    ax_dict={\"main_ax\":ax[0,k],\"ratio_ax\":ax[1,k]},\n",
    "                    rp_ylabel=r\"Ratio\",\n",
    "                    rp_num_label=\"Flow Generated\",\n",
    "                    rp_denom_label=\"MC Simulatied\",\n",
    "                    rp_uncert_draw_type=\"line\",  # line or bar\n",
    "                )\n",
    "                ax[0,k].set_xlabel(\"\")\n",
    "#                 if quantile and v==\"m\" and plot_vline:\n",
    "#                     ax[0,k].hist(m[m_t<np.quantile(m_t,0.1)],histtype='step',bins=bins,alpha=1,color=\"red\",label=\"10% quantile gen\",hatch=\"/\")\n",
    "#                     ax[0,k].vlines(np.quantile(m_t,0.1),0,np.max(h[:]),color=\"red\",label='10% quantile train')\n",
    "                    \n",
    "                ax[1,k].set_ylim(0.25,2)\n",
    "                ax[0,k].set_xlim(a,b)\n",
    "                ax[1,k].set_xlabel(name,fontweight=\"bold\")\n",
    "                ax[1,k].set_xlim(a,b)\n",
    "                ax[0,k].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "                ax[1,k].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "                \n",
    "#                 if plot_vline:\n",
    "#                        ax[0,k].legend([\"Generated\",\"Training\",\"10% quantile Gen\",\"10% quantile Sim\"] )\n",
    "#                 else:\n",
    "#                       ax[0,k].legend([\"Flow Generated\",\"MC Simulated\"] )\n",
    "            except:\n",
    "                print(\"mass plot failed reverting to simple plot mass bins\")\n",
    "                plt.close()\n",
    "                plt.figure()\n",
    "                _,b,_=plt.hist(m_t,15,label=\"MC Simulated\",alpha=0.5)\n",
    "                plt.hist(m,b,label=\"Flow Generated\",alpha=0.5)\n",
    "                plt.legend()  \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            \n",
    "#             plt.xlabel(name)\n",
    "            plt.tight_layout(pad=1)\n",
    "            k+=1\n",
    "        if save:\n",
    "            if v!=\"m\":\n",
    "                 self.summary.add_figure(\"inclusive\"+v,fig,self.step)\n",
    "            else:\n",
    "                self.summary.add_figure(\"jet_mass\",fig,self.step)\n",
    "#             print(\"added figure\")\n",
    "#             self.summary.close()\n",
    "        else:\n",
    "            plt.savefig(\"{}_oversample_{}\".format(self.p,v))\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "    def plot_mass(self,m,m_t,save=False,quantile=False,bins=15,plot_vline=False,title=\"\"):\n",
    "        #This creates a histogram of the inclusive distributions and calculates the mass of each jet\n",
    "        #and creates a histogram of that\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        #if quantile, this also creates a histogram of a subsample of the generated data, \n",
    "        # where the mass used to condition the flow is in the first 10% percentile of the simulated mass dist\n",
    "        i=0\n",
    "        k=0\n",
    "        fig,ax=plt.subplots(2,4,gridspec_kw={'height_ratios': [3, 1]},figsize=(20,5))\n",
    "        plt.suptitle(title,fontweight=\"bold\")\n",
    "        for v,name in zip([\"eta\",\"phi\",\"pt\",\"m\"],[r\"$\\eta^{rel}$\",r\"$\\phi^{rel}$\",r\"$p_T^{rel}$\",r\"$m^{rel}$\"]):\n",
    "            \n",
    "            if v!=\"m\":\n",
    "                a=min(np.quantile(self.gen[:,i],0.001),np.quantile(self.test_set[:,i],0.001))\n",
    "                b=max(np.quantile(self.gen[:,i],0.999),np.quantile(self.test_set[:,i],0.999))     \n",
    "                \n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h.fill(self.gen[:,i],weight=1/self.weight)\n",
    "                h2.fill(self.test_set[:,i])\n",
    "                i+=1\n",
    "            else:\n",
    "                a=min(np.quantile(m_t,0.001),np.quantile(m,0.001))\n",
    "                b=max(np.quantile(m_t,0.999),np.quantile(m,0.999))\n",
    "                a=np.quantile(m_t,0.001)\n",
    "                b=np.quantile(m_t,0.999)\n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                bins = h.axes[0].edges\n",
    "                h.fill(m)#,weight=1/self.weight)\n",
    "                h2.fill(m_t)\n",
    "            \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            try:\n",
    "                main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "                    h2,\n",
    "                    ax_dict={\"main_ax\":ax[0,k],\"ratio_ax\":ax[1,k]},\n",
    "                    rp_ylabel=r\"Ratio\",\n",
    "                    rp_num_label=\"Flow Generated\",\n",
    "                    rp_denom_label=\"MC Simulatied\",\n",
    "                    rp_uncert_draw_type=\"line\",  # line or bar\n",
    "                )\n",
    "                ax[0,k].set_xlabel(\"\")\n",
    "#                 if quantile and v==\"m\" and plot_vline:\n",
    "#                     ax[0,k].hist(m[m_t<np.quantile(m_t,0.1)],histtype='step',bins=bins,alpha=1,color=\"red\",label=\"10% quantile gen\",hatch=\"/\")\n",
    "#                     ax[0,k].vlines(np.quantile(m_t,0.1),0,np.max(h[:]),color=\"red\",label='10% quantile train')\n",
    "                    \n",
    "                ax[1,k].set_ylim(0.25,2)\n",
    "                ax[0,k].set_xlim(a,b)\n",
    "                ax[1,k].set_xlabel(name,fontweight=\"bold\")\n",
    "                ax[1,k].set_xlim(a,b)\n",
    "                ax[0,k].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "                ax[1,k].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "                \n",
    "#                 if plot_vline:\n",
    "#                        ax[0,k].legend([\"Generated\",\"Training\",\"10% quantile Gen\",\"10% quantile Sim\"] )\n",
    "#                 else:\n",
    "#                       ax[0,k].legend([\"Flow Generated\",\"MC Simulated\"] )\n",
    "            except:\n",
    "                print(\"mass plot failed reverting to simple plot mass bins\")\n",
    "                plt.close()\n",
    "                plt.figure()\n",
    "                _,b,_=plt.hist(m_t,15,label=\"MC Simulated\",alpha=0.5)\n",
    "                plt.hist(m,b,label=\"Flow Generated\",alpha=0.5)\n",
    "                plt.legend()  \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            \n",
    "#             plt.xlabel(name)\n",
    "            plt.tight_layout(pad=1)\n",
    "            k+=1\n",
    "        if save:\n",
    "            if v!=\"m\":\n",
    "                 self.summary.add_figure(\"inclusive\"+v,fig,self.step)\n",
    "            else:\n",
    "                self.summary.add_figure(\"jet_mass\",fig,self.step)\n",
    "#             print(\"added figure\")\n",
    "#             self.summary.close()\n",
    "        else:\n",
    "            plt.savefig(\"{}_inclusive_{}\".format(self.p,v))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def losses(self,save=False):\n",
    "        '''This plots the different losses vs epochs'''\n",
    "        fig=plt.figure()\n",
    "        hep.cms.label(\"Private Work\",data=None,lumi=None,year=None)\n",
    "        plt.xlabel('step')\n",
    "        plt.ylabel('loss')\n",
    "        ln1=plt.plot(self.model.logprobs,label='log$(p_{gauss}(x_{data}))$')\n",
    "        if \"calc_massloss\" in self.config.keys() and self.config[\"calc_massloss\"]:\n",
    "            plt.twinx()\n",
    "            ln2=plt.plot(self.model.mlosses,label=r'mass mse $\\times$ {}'.format(self.config[\"lambda\"]),color='orange')\n",
    "            plt.ylabel(\"MSE\")\n",
    "            plt.yscale(\"log\")\n",
    "            ln1+=ln2\n",
    "        labs=[l.get_label() for l in ln1]\n",
    "        plt.legend(ln1,labs)\n",
    "        plt.tight_layout(pad=2)\n",
    "        if save:\n",
    "            self.summary.add_figure(\"losses\",fig,self.step)\n",
    "#             self.summary.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "   \n",
    "\n",
    "    def plot_correlations(self,save=True):\n",
    "        #Plots correlations between all particles for i=0 eta,i=1 phi,i=2 pt\n",
    "        self.plot_corr(i=0,save=save)\n",
    "        self.plot_corr(i=1,save=save)\n",
    "        self.plot_corr(i=2,save=save)\n",
    "\n",
    "    def plot_corr(self,i=0,names=[\"$\\eta^{rel}$\",\"$\\phi^{rel}$\",\"$p_T$\"],save=True):\n",
    "        if i==2:\n",
    "            c=1\n",
    "        else:\n",
    "            c=1\n",
    "        df_g=pd.DataFrame(self.gen.reshape(-1,90).detach().numpy()[:,range(i,90,3)])\n",
    "        df_h=pd.DataFrame(self.test_set.reshape(-1,90).detach().numpy()[:,range(i,90,3)])\n",
    "        fig,ax=plt.subplots(ncols=2,figsize=(20,10))\n",
    "        corr_g = ax[0].matshow(df_g.corr())\n",
    "        corr_g.set_clim(-c,c)\n",
    "        divider = make_axes_locatable(ax[0])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        cbar=fig.colorbar(corr_g,cax=cax)\n",
    "        corr_h = ax[1].matshow(df_h.corr())\n",
    "        corr_h.set_clim(-c,c)\n",
    "        divider = make_axes_locatable(ax[1])\n",
    "        cax2 = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        cbar=fig.colorbar(corr_h,cax=cax2)\n",
    "        plt.suptitle(\"{} Correlation between Particles\".format(names[i]),fontweight=\"bold\")\n",
    "        ax[0].set_title(\"Flow Generated\",fontweight=\"bold\")\n",
    "        ax[1].set_title(\"MC Simulated\",fontweight=\"bold\")\n",
    "        ax[0].set_xlabel(\"Particles\",fontweight=\"bold\")\n",
    "        ax[0].set_ylabel(\"Particles\",fontweight=\"bold\")\n",
    "        ax[1].set_xlabel(\"Particles\",fontweight=\"bold\")\n",
    "        ax[1].set_ylabel(\"Particles\",fontweight=\"bold\")\n",
    "        title=[\"corr_eta\",\"corr_phi\",\"corr_pt\"]\n",
    "        if save:\n",
    "                \n",
    "                self.summary.add_figure(title[i],fig,self.step)    \n",
    "    #             self.summary.close()\n",
    "        else:\n",
    "                plt.savefig(\"{}_{}\".format(self.p,title[i]))\n",
    "                plt.show()\n",
    "\n",
    "    def var_part(self,true,gen,true_n,gen_n,m_true,m_gen,form=2,save=True):\n",
    "        labels=[\"$\\eta^{rel}$\",\"$\\phi^{rel}$\",\"$p^{rel}_T$\",\"$m^{rel}$\"]\n",
    "        names=[\"eta\",\"phi\",\"pt\",\"m\"]\n",
    "        n,counts=torch.unique(true_n,return_counts=True)\n",
    "        for j in range(4):\n",
    "            fig,ax=plt.subplots(ncols=2,nrows=2,figsize=(15,15))\n",
    "\n",
    "            k=-1\n",
    "            ntemp=n[-form**2:]\n",
    "\n",
    "            \n",
    "            for i in list(ntemp)[::-1]: \n",
    "                k+=1\n",
    "                i=int(i)\n",
    "\n",
    "                if names[j]!=\"m\":\n",
    "                    a=np.quantile(self.test_set[true_n.reshape(-1)==i,:].reshape(-1,3)[:,j],0.001)\n",
    "                    b=np.quantile(self.test_set[true_n.reshape(-1)==i,:].reshape(-1,3)[:,j],0.999)    \n",
    "                    h=hist.Hist(hist.axis.Regular(15,a,b))\n",
    "                    h2=hist.Hist(hist.axis.Regular(15,a,b))\n",
    "                    bins = h.axes[0].edges\n",
    "\n",
    "                    ax[k//form,k%form].legend()\n",
    "                    h.fill(self.gen[gen_n.reshape(-1)==i,:].reshape(-1,3)[:,j])\n",
    "                    h2.fill(self.test_set[true_n.reshape(-1)==i,:].reshape(-1,3)[:,j])\n",
    "                    \n",
    "                else:\n",
    "                    a=np.quantile(m_true[true_n.reshape(-1)==i],0.001)\n",
    "                    b=np.quantile(m_gen[gen_n.reshape(-1)==i],0.999)\n",
    "  \n",
    "                    h=hist.Hist(hist.axis.Regular(15,a,b,label=labels[j]))\n",
    "                    h2=hist.Hist(hist.axis.Regular(15,a,b,label=labels[j]))\n",
    "                    bins = h.axes[0].edges\n",
    "                    h.fill(m_gen[gen_n.reshape(-1)==i])\n",
    "                    h2.fill(m_true[true_n.reshape(-1)==i])\n",
    "                    \n",
    "\n",
    "                h.plot1d(    ax=ax[k//2,k%2],label=\"Flow Simulated\")  # line or bar)\n",
    "                h2.plot1d(    ax=ax[k//2,k%2],label=\"MC Generated\")  # line or bar)\n",
    "                ax[k//2,k%2].set_title(\"{} Distribution for jets with {} particles\".format(labels[j],i))\n",
    "\n",
    "                ax[k//2,k%2].set_xlabel(labels[j])\n",
    "                ax[k//2,k%2].set_ylabel(\"Counts\",fontweight=\"bold\")\n",
    "                ax[k//2,k%2].set_xlim(a,b)\n",
    "                ax[k//2,k%2].legend()\n",
    "                #plt.tight_layout(pad=2)\n",
    "\n",
    "            if save:\n",
    "                self.summary.add_figure(\"jet{}_{}\".format(i//3+1,names[i%3]),fig,global_step=self.step)\n",
    "                self.summary.close()\n",
    "            else:\n",
    "                plt.savefig(\"jet{}_{}\".format(self.p,i//3+1,names[j]))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ce908-5525-4d87-9dbb-649d5b2db02a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eeec8f7-62f4-4d96-877e-32bb9f53b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'autoreg': False, 'context_features': 0, 'network_layers': 3, 'network_layers_nf': 2, 'network_nodes_nf': 256, 'batch_size': 1024, 'coupling_layers': 15, 'lr': 0.001, 'batchnorm': False, 'bins': 5, 'tail_bound': 6, 'limit': 150000, 'n_dim': 3, 'dropout': 0.2, 'canonical': False, 'max_steps': 100000, 'lambda': 1, 'name': 'Transflow_best', 'disc': False, 'variable': 1, 'parton': 't', 'wgan': False, 'corr': True, 'num_layers': 4, 'freq': 6, 'n_part': 30, 'fc': False, 'hidden': 500, 'heads': 4, 'l_dim': 100, 'lr_g': 0.0004327405312571664, 'lr_d': 0.0004327405312571664, 'lr_nf': 0.000722, 'sched': 'cosine2', 'opt': 'RMSprop', 'max_epochs': 3200, 'mass': True, 'no_hidden': False, 'clf': True, 'val_check': 50, 'frac_pretrain': 80, 'seed': 69, 'quantile': False}, 'hyperopt': True, 'num_batches': 112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/beegfs/desy/user/kaechben/.conda/envs/jetnet/lib/python3.8/site-packages/torch/nn/init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/kaechben/JetNet_NF/LitJetNet/LitNF/lit_nf.py:269: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  nn.init.xavier_normal(p)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "best_hparam=\"/beegfs/desy/user/kaechben/Transflow_best/lightning_logs/version_72/hparams.yaml\"\n",
    "with open(best_hparam, 'r') as stream:\n",
    "        config=yaml.load(stream,Loader=yaml.Loader)\n",
    "        print(config)\n",
    "        config=config[\"config\"]\n",
    "data_module = JetNetDataloader(config,) #this loads the data\n",
    "data_module.setup(\"train\")\n",
    "# data=data_module.scaler.inverse_transform(data_module.data[:,:90]).reshape(-1,30,3)\n",
    "model = TransGan(config,False,data_module.num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78435b12-78a4-4ada-aa8e-351284ff58eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/beegfs/desy/user/kaechben/.conda/envs/jetnet/lib/python3.8/site-packages/jetnet/evaluation/gen_metrics.py:239: RuntimeWarning: Recommended number of jets for FPND calculation is 50000\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model=\"/beegfs/desy/user/kaechben/Transflow_best/epoch=1749-val_fpnd=0.08-val_w1m=0.0008.ckpt\"\n",
    "batch=data_module.test_set\n",
    "model=model.load_from_checkpoint(best_model)\n",
    "model.load_datamodule(data_module)\n",
    "mask = batch[:, 90:].cpu()\n",
    "batch = batch[:, :90].cpu()\n",
    "mask_test = model.sample_n(mask)\n",
    "mask_test=mask\n",
    "model.dis_net.train()\n",
    "model.gen_net.train()\n",
    "model.data_module.scaler.to(\"cpu\")\n",
    "batch = batch.to(\"cpu\")\n",
    "model.flow = model.flow.to(\"cpu\")\n",
    "model.dis_net = model.dis_net.cpu()\n",
    "model.gen_net = model.gen_net.cpu()\n",
    "\n",
    "gen, true, z, fake_scaled, true_scaled, z_scaled = model.sampleandscale(batch, mask=None,scale=True)\n",
    "if model.config[\"mass\"]:\n",
    "    m_t = mass(batch.reshape(len(batch), model.n_part * model.n_dim), model.config[\"canonical\"])\n",
    "    m_f = mass(gen.reshape(len(batch), model.n_part * model.n_dim), model.config[\"canonical\"])\n",
    "scores_fake = model.dis_net(gen, None if not model.config[\"mass\"] else m_f, mask=mask_test)\n",
    "scores_real = model.dis_net(batch.reshape(len(batch), model.n_part, model.n_dim), None if not model.config[\"mass\"] else m_t, mask=mask)\n",
    "\n",
    "\n",
    "\n",
    "true_scaled, fake_scaled, z_scaled = (true_scaled.reshape(-1, 90), fake_scaled.reshape(-1, 90), z_scaled.reshape(-1, 90))\n",
    "# Reverse Standard Scaling (this has nothing to do with flows, it is a standard preprocessing step)\n",
    "m_t = mass(\n",
    "    true_scaled[:, : model.n_dim * model.n_part].to(model.device),\n",
    "    model.config[\"canonical\"],\n",
    ").cpu()\n",
    "m_gen = mass(z_scaled[:, : model.n_dim * model.n_part], model.config[\"canonical\"]).cpu()\n",
    "m_c = mass(fake_scaled[:, : model.n_dim * model.n_part], model.config[\"canonical\"]).cpu()\n",
    "for i in range(30):\n",
    "    i = 2 + 3 * i\n",
    "    # gen[gen[:,i]<0,i]=0\n",
    "    fake_scaled[fake_scaled[:, i] < 0, i] = 0\n",
    "    true_scaled[true_scaled[:, i] < 0, i] = 0\n",
    "# Some metrics we track\n",
    "cov, mmd = cov_mmd(fake_scaled.reshape(-1, model.n_part, model.n_dim), true_scaled.reshape(-1, model.n_part, model.n_dim), use_tqdm=False)\n",
    "try:\n",
    "    fpndv = fpnd(fake_scaled.reshape(-1, model.n_part, model.n_dim).numpy(), use_tqdm=False, jet_type=model.config[\"parton\"])\n",
    "    print(fpndv)\n",
    "except:\n",
    "    fpndv = 1000\n",
    "w1m_ = w1m(fake_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))[0]\n",
    "w1p_ = w1p(fake_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))[0]\n",
    "w1efp_ = w1efp(fake_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02843b6-9a69-4a77-b566-ba80e2bfc9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0007269817792907111,\n",
       " 2.2933309130581175e-05,\n",
       " 0.07581580039152414,\n",
       " 0.5810000000000001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1m_,w1efp_,fpndv,cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc996725-f469-44e2-b90f-9762f04bccca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2590654566.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [5]\u001b[0;36m\u001b[0m\n\u001b[0;31m    fake_plot=fake_plot*(~mask_test[mask_test.sum(1)>k].reshape(-1,30data_module\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p=parton\n",
    "model.n_dim=90\n",
    "k=5\n",
    "fake_plot=fake_scaled[mask_test.sum(1)>k]\n",
    "fake_plot=fake_plot*(~mask_test[mask_test.sum(1)>k].reshape(-1,30data_module\n",
    "fake_scaled=fake_scaled*(~mask_test.reshape(-1,30,1))\n",
    "true_scaled=true_scaled*(~mask.reshape(-1,30,1))\n",
    "\n",
    "true=true_scaled[mask.sum(1)>k]\n",
    "m_t=mass(true,(~mask[mask.sum(1)>k]))\n",
    "m_gen=mass(fake_plot,(~mask_test[mask_test.sum(1)>k]))\n",
    "plot=plotting_paper(model=model,gen=fake_plot.reshape(-1,90),true=true.reshape(-1,90),config=model.config,step=model.global_step,p=parton,logger=None)\n",
    "plot.plot_marginals(ith=7,save=False,title=\"Marginal Distributions, {} Dataset\".format(\"Top-Quark\" if p==\"t\" else \"Gluon\" if p==\"g\" else \"Light-Quark\"))\n",
    "plot.plot_mass(m_t.cpu().numpy(),m_gen.cpu().numpy(),save=False,bins=30,quantile=False,title=\"Inclusive Distributions, top-quark Dataset\")\n",
    "# plot.var_part(true=true[:,:model.n_dim],gen=test[:,:model.n_dim],true_n=n_true,gen_n=n_test,m_true=m_t,m_gen=m_test ,save=False)\n",
    "plot.plot_corr(i=0,save=False)\n",
    "plot.plot_corr(i=1,save=False)            \n",
    "plot.plot_corr(i=2,save=False)     \n",
    "plot.plot_mass_only(m_t.cpu().numpy(),m_gen.cpu().numpy(),bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12d314-c920-4e6f-ade5-a946676b084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w1m(fake_plot.reshape(-1,30,3),true.reshape(-1,30,3)))\n",
    "fpnd(fake_scaled,\"q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd6874-881b-44cd-aea1-474b0d9b95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "_,bins,_=plt.hist(m_gen.numpy(),bins=50,alpha=0.5)\n",
    "plt.hist(m_t.numpy(),bins=bins,alpha=0.5)\n",
    "plt.savefig(\"masses\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc1a6d-333c-48fb-89c8-885ec5e9e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd555d0-107c-4502-a1c7-8c7f0a4a05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mean_sd(mean, sd):\n",
    "    \"\"\"round mean and standard deviation to most significant digit of sd and apply latex formatting\"\"\"\n",
    "    decimals = -int(np.floor(np.log10(sd)))\n",
    "    decimals -= int((sd * 10 ** decimals) >= 9.5)\n",
    "\n",
    "    if decimals < 0:\n",
    "        ten_to = 10 ** (-decimals)\n",
    "        if mean > ten_to:\n",
    "            mean = ten_to * (mean // ten_to)\n",
    "        else:\n",
    "            mean_ten_to = 10 ** np.floor(np.log10(mean))\n",
    "            mean = mean_ten_to * (mean // mean_ten_to)\n",
    "        sd = ten_to * (sd // ten_to)\n",
    "        decimals = 0\n",
    "\n",
    "    if mean >= 1e3 and sd >= 1e3:\n",
    "        mean = np.round(mean * 1e-3)\n",
    "        sd = np.round(sd * 1e-3)\n",
    "        return f\"${mean:.{decimals}f}$k $\\\\pm {sd:.{decimals}f}$k\"\n",
    "    else:\n",
    "        return f\"${mean:.{decimals}f} \\\\pm {sd:.{decimals}f}$\"\n",
    "print_table=results_sum.copy().drop(\"fpndnf\",1)\n",
    "print_table.index=[\"g\",\"t\"]#\"q\"\n",
    "print_table[\"model\"]=[\"g\",\"t\"]#\"q\"\n",
    "\n",
    "print_table.loc[:,\"w1m_\"]*=1000\n",
    "print_table.loc[:,\"w1p_\"]*=1000\n",
    "print_table.loc[:,\"w1efp_\"]*=100000\n",
    "print_table.loc[:,\"pmm\"]*=1000\n",
    "print_table.loc[:,\"pmp\"]*=1000\n",
    "print_table.loc[:,\"pme\"]*=100000\n",
    "print_table.loc[\"MP-MP-g\",:]=np.array([0.7,0.9,0.7,0.12,0.56,0.037,0.2,0.3,0.7,\"MP-MP\"])\n",
    "\n",
    "print_table.loc[\"MPLFC-MP-g\",:]=np.array([0.69,1.8,0.9,0.2,0.54,0.037,.07,.3,.2,\"MP_LFC-MP\"])\n",
    "print_table.loc[\"MP-MP-q\",:]=np.array([0.6,4.9,0.7,0.35,0.50,0.026,.2,.5,.4,\"MP-MP\"])\n",
    "\n",
    "print_table.loc[\"MPLFC-MP-q\",:]=np.array([0.7,2.6,0.9,0.08,0.52,0.037,.2,.4,.9,\"MP_LFC-MP\"])\n",
    "\n",
    "print(print_table)\n",
    "\n",
    "print_table.loc[\"MP-MP-t\",:]=np.array([0.6,2.3,2,0.37,0.57,0.071,.2,.3,1,\"MP-MP\"])\n",
    "print_table.loc[\"MPLFC-MP-t\",:]=np.array([0.9,2.2,2,0.93,0.56,0.073,.3,.7,1,\"MP_LFC-MP\"])\n",
    "print_table.loc[:,\"w1m_\"]=print_table.apply(lambda x:format_mean_sd(float(x[\"w1m_\"]),float(x[\"pmm\"])),axis=1)\n",
    "print_table.loc[:,\"w1efp_\"]=print_table.apply(lambda x:format_mean_sd(float(x[\"w1efp_\"]),float(x[\"pme\"])),axis=1)\n",
    "print_table.loc[:,\"w1p_\"]=print_table.apply(lambda x:format_mean_sd(float(x[\"w1p_\"]),float(x[\"pmp\"])),axis=1)\n",
    "\n",
    "\n",
    "print_table.loc[:,\"cov\"]=print_table.loc[:,\"cov\"].astype(float).map('{:.2f}'.format)\n",
    "print_table.loc[:,\"fpndv\"]=print_table.loc[:,\"fpndv\"].astype(float).map('{:.2f}'.format)\n",
    "print_table.loc[:,\"mmd\"]=print_table.loc[:,\"mmd\"].astype(float).map('{:.3f}'.format)\n",
    "print_table.loc[:,\"pmm\"]=print_table.loc[:,\"pmm\"].astype(float).map('{:,.2f}'.format)\n",
    "\n",
    "print_table.loc[:,\"pmp\"]=print_table.loc[:,\"pmp\"].astype(float).map('{:,.2f}'.format)\n",
    "\n",
    "print_table.loc[:,\"pme\"]=print_table.loc[:,\"pme\"].astype(float).map('{:,.2f}'.format)\n",
    "print_table.loc[:,\"parton\"]=print_table.index.str[-1]\n",
    "# print_table.loc[:,\"val_w1m\"]=\"$\"+print_table[\"val_w1m\"].map(str)+\"\\pm\"+print_table[\"pmm\"].map(str)+\"$\"\n",
    "# print_table.loc[:,\"val_w1p\"]=\"$\"+print_table[\"val_w1p\"].map(str)+\"\\pm\"+print_table[\"pmp\"].map(str)+\"$\"\n",
    "# print_table.loc[:,\"val_w1efp\"]=\"$\"+print_table[\"val_w1efp\"].map(str)+\"\\pm\"+print_table[\"pme\"].map(str)+\"$\"\n",
    "print_table.loc[:,\"cov\"]=\"$\"+print_table[\"cov\"].map(str)+\"$\"\n",
    "print_table.loc[:,\"fpndv\"]=\"$\"+print_table[\"fpndv\"].map(str)+\"$\"\n",
    "print_table.loc[:,\"mmd\"]=\"$\"+print_table[\"mmd\"].map(str)+\"$\"\n",
    "\n",
    "# print_table.loc[:,\"model\"]=print_table[\"model\"].str.replace(\"c0\",\"VNF\").str.replace(\"cc\",\"NFCC\").str.replace(\"c\",\"NFC\").str.replace(\"1\",\"\\ (m)\").str.replace(\"2\",\"\\ (m,n)\").str.replace(\"q\",\"\").str.replace(\"g\",\"\").str.replace(\"t\",\"\")\n",
    "index=[\"MP-MP-g\",\"MPLFC-MP-g\",\"g\",\"MP-MP-t\",\"MPLFC-MP-t\",\"t\"]#\"MP-MP-q\",\"MPLFC-MP-q\",\"q\"\n",
    "\n",
    "print_table=print_table.loc[index,:]\n",
    "final_table=pd.DataFrame()\n",
    "tex=\"\"\n",
    "for p in [\"g\",\"t\"]:#\"q\",\n",
    "    temp=print_table[print_table[\"parton\"]==p]\n",
    "\n",
    "    for col in print_table.drop(\"model\",axis=1).columns:\n",
    "        \n",
    "        if col not in [\"w1m_\",\"w1p_\",\"w1efp_\",\"fpndv\",\"cov\",\"mmd\" ]:\n",
    "            continue\n",
    "        \n",
    "        temp_index=temp[col].str.replace(\"$\",\"\").str.split(\"\\\\\").str[0].astype(float)\n",
    "        mins=temp_index==temp_index.min() if col!=\"cov\" else temp_index==temp_index.max()\n",
    "        temp.loc[mins,col]=\"$\\mathbf{\"+temp.loc[mins,col].astype(str).str.replace(\"$\",\"\")+\"}$\"\n",
    "    temp=temp[[\"model\",\"w1m_\",\"w1p_\",\"w1efp_\",\"fpndv\",\"cov\",\"mmd\"]]\n",
    "    temp.columns=[\"model\",\"$W_1^M (\\times 10^{-3})$\",\"$W_1^P (\\times 10^{-3})$\",\"$W_1^{EFP}(\\times 10^{-5})$\",\"FPND\",r\"COV $\\uparrow$\",\"MMD\"]\n",
    "    text=temp.to_latex(index=False,escape=False)\n",
    "    parton=\"Gluon\" if p==\"g\" else \"Light Quark\" if p==\"q\" else \"Top Quark\"\n",
    "    tex+=\"\\multirow{7}{*}{\"+parton+\"} & \"+text.split(\"MMD \\\\\\\\\")[1].split(\"\\\\bottomrule\")[0].replace(\"\\\\\\\\\",\"\\\\\\\\&\").replace(\"\\\\midrule\",\"\").replace(\"MP_LFC\",\"MP\\_LFC\").replace(\"  \",\"\")[:-2]+\"\\cline{1-8}\" \n",
    "    tex+=\"\\n\"\n",
    "print(tex)\n",
    "\n",
    "    #     final_table=final_table.append(temp)\n",
    "\n",
    "# print(final_table.to_latex(index=False,escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343caabc-76ec-47f7-93cc-c5c9535a3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetnet_dataloader import JetNetDataloader\n",
    "config[\"parton\"]=\"q\"\n",
    "data_module_q=JetNetDataloader(config)\n",
    "data_module_q.setup(\"validation\")\n",
    "config[\"parton\"]=\"t\"\n",
    "data_module_t=JetNetDataloader(config)\n",
    "data_module_t.setup(\"validation\")\n",
    "config[\"parton\"]=\"g\"\n",
    "data_module_g=JetNetDataloader(config)\n",
    "data_module_g.setup(\"validation\")\n",
    "_,bins,_=plt.hist(data_module_q.n,label=\"q\",histtype=\"step\",bins=np.linspace(0,30,30))\n",
    "plt.hist(data_module_t.n,bins,label=\"t\",histtype=\"step\")\n",
    "plt.hist(data_module_g.n,bins,label=\"g\",histtype=\"step\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"number particles in jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561ab3b-06a3-4403-bbae-8b0a5badc542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e897894-5c7a-47c0-bc1a-f259b0803861",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=data_module_t.data[:,:90].reshape(-1,30,3)\n",
    "mask_t=data_module_t.data[:,90:].bool()\n",
    "t=model.scale(t,mask_t)\n",
    "q=data_module_q.data[:,:90].reshape(-1,30,3)\n",
    "mask_q=data_module_q.data[:,90:].bool()\n",
    "q=model.scale(q,mask_q)\n",
    "g=data_module_g.data[:,:90].reshape(-1,30,3)\n",
    "mask_g=data_module_g.data[:,90:].bool()\n",
    "g=model.scale(g,mask_g)\n",
    "m=mass(t.reshape(-1,90),~mask_t)\n",
    "plt.hist(m.numpy(),30,label=\"t\",histtype=\"step\")\n",
    "\n",
    "m=mass(q.reshape(-1,90),~mask_q)\n",
    "plt.hist(m.numpy(),30,label=\"q\",histtype=\"step\")\n",
    "\n",
    "m=mass(g.reshape(-1,90),~mask_g)\n",
    "plt.hist(m.numpy(),30,label=\"q\",histtype=\"step\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Mass\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(t.sum(axis=1).numpy()[:,2],30,label=\"t\",histtype=\"step\")\n",
    "plt.hist(q.sum(axis=1).numpy()[:,2],30,label=\"q\",histtype=\"step\")\n",
    "plt.hist(g.sum(axis=1).numpy()[:,2],30,label=\"g\",histtype=\"step\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818416fa-83b4-41c9-b837-d1f3ab81d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_dim=3\n",
    "t=data_module_t.data[:,:90].reshape(-1,30,3)\n",
    "mask_t=data_module_t.data[:,90:].bool()\n",
    "t=model.scale(t,mask_t)\n",
    "q=data_module_q.data[:,:90].reshape(-1,30,3)\n",
    "mask_q=data_module_q.data[:,90:].bool()\n",
    "q=model.scale(q,mask_q)\n",
    "g=data_module_g.data[:,:90].reshape(-1,30,3)\n",
    "mask_g=data_module_g.data[:,90:].bool()\n",
    "g=model.scale(g,mask_g)\n",
    "fig,ax=plt.subplots(5,6,figsize=(20,20))\n",
    "for i in range(30):\n",
    "    _,bins,_=ax[i//6,i%6].hist(t[:,i,2].numpy(),bins=40,label=\"t\",histtype=\"step\")\n",
    "    ax[i//6,i%6].hist(q[:,i,2].numpy(),bins=bins,label=\"q\",histtype=\"step\")\n",
    "    ax[i//6,i%6].hist(g[:,i,2].numpy(),bins=bins,label=\"g\",histtype=\"step\")\n",
    "    ax[i//6,i%6].legend()\n",
    "plt.suptitle(r\"Jet Particles ordered by $p_T$ distribution\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9f440-d1ed-41c7-9d03-6d3a25b5dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(5,6,figsize=(20,20))\n",
    "for i in range(30):\n",
    "\n",
    "    _,bins,_=ax[i//6,i%6].hist(t[:,i,0].numpy(),bins=40,label=\"t\",histtype=\"step\")\n",
    "    ax[i//6,i%6].hist(q[:,i,0].numpy(),bins=bins,label=\"q\",histtype=\"step\")\n",
    "    ax[i//6,i%6].hist(g[:,i,0].numpy(),bins=bins,label=\"g\",histtype=\"step\")\n",
    "    ax[i//6,i%6].legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7667cb-1b69-49dd-92eb-8bc8d1550ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(5,6,figsize=(20,20))\n",
    "for i in range(30):\n",
    "\n",
    "    _,bins,_=ax[i//6,i%6].hist(t[:,i,1].numpy(),bins=40,label=\"t\",histtype=\"step\")\n",
    "    ax[i//6,i%6].hist(q[:,i,1].numpy(),bins=bins,label=\"q\",histtype=\"step\")\n",
    "    ax[i//6,i%6].hist(g[:,i,1].numpy(),bins=bins,label=\"g\",histtype=\"step\")\n",
    "    ax[i//6,i%6].legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d5641-7b83-492f-8640-21bcdaf01b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfbac4-c9cc-4cd5-913a-bffd7351f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"/beegfs/desy/user/kaechben/{}/summary.csv\".format(\"Transflow_working\"))\n",
    "# df1=pd.read_csv(\"/beegfs/desy/user/kaechben/{}/summary.csv\".format(\"Transflow_reloaded\"))\n",
    "# df2=pd.read_csv(\"/beegfs/desy/user/kaechben/{}/summary.csv\".format(\"Transflow_reloaded2\"))\n",
    "df=pd.read_csv(\"/beegfs/desy/user/kaechben/{}/summary.csv\".format(\"Transflow_gettingthere_q\"))\n",
    "for name in [\"Transflow_gettingthere_q\",\"Transflow_gettingthere_t\",\"Transflow_gettingthere_g\",\n",
    "            \"Transflow_final_q\",\"Transflow_final_t\",\"Transflow_final_g\"]:\n",
    "    temp=pd.read_csv(\"/beegfs/desy/user/kaechben/{}/summary.csv\".format(name))\n",
    "    df=pd.concat((df,temp))\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows',None)\n",
    "# df=df.append(df1).append(df2)\n",
    "df.loc[:,\"val_w1m\"]*=1000\n",
    "df.loc[:,\"val_w1p\"]*=1000\n",
    "df.loc[:,\"val_w1efp\"]*=100000\n",
    "df.loc[:,\"val_w1m\"]=df.loc[:,\"val_w1m\"].round(2)\n",
    "df.loc[:,\"val_cov\"]=df.loc[:,\"val_cov\"].round(2)\n",
    "df.loc[:,\"val_fpnd\"]=df.loc[:,\"val_fpnd\"].round(2)\n",
    "df.loc[:,\"val_mmd\"]=df.loc[:,\"val_mmd\"].round(3)\n",
    "df.loc[:,\"val_w1p\"]=df.loc[:,\"val_w1p\"].round(2)\n",
    "df.loc[:,\"val_w1efp\"]=df.loc[:,\"val_w1efp\"].round(2)\n",
    "\n",
    "df.sort_values(\"val_fpnd\")[[\"path_index\",\"val_w1m\",\"val_w1p\",\"val_w1efp\",\"val_fpnd\",\"val_cov\",\"val_mmd\"]]\n",
    "#df=df[df.path_index.str.find(\"run17_08\")>-1].sort_values(\"val_fpnd\")\n",
    "df.sort_values(\"val_fpnd\")[[\"path_index\",\"val_w1m\",\"val_w1p\",\"val_w1efp\",\"val_fpnd\",\"val_cov\",\"val_mmd\"]]\n",
    "\n",
    "# best_q=df.iloc[2,:]\n",
    "\n",
    "\n",
    "# df.iloc[302,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e007c2-9a09-4ba5-9048-272c4b032722",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df=backup[backup.mass==True]\n",
    "# df=df[df.wgan==False]\n",
    "# df=df[df.opt==\"Adam\"]\n",
    "print(len(df))\n",
    "for key in [\"batch_size\",\"sched\",\"opt\",\"lr_g\",\"mass\",\"freq\",\"wgan\",\"hidden\",\"num_layers\",\"no_hidden\",\"heads\",\"mass\",\"quantile\",\"norm\"]:\n",
    "    try:\n",
    "        if len(df[key].value_counts())==1:\n",
    "            continue\n",
    "        fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "        df.loc[df[\"opt\"]==\"Adam\",\"opt\"]=0\n",
    "        df.loc[df[\"opt\"]==\"AdamW\",\"opt\"]=1\n",
    "        df.loc[df[\"opt\"]==\"RMSprop\",\"opt\"]=2\n",
    "        df.loc[df[\"sched\"]!=df[\"sched\"],\"sched\"]=0\n",
    "        df.loc[df[\"sched\"]==\"cosine\",\"sched\"]=1\n",
    "        df.loc[df[\"sched\"]==\"cosine2\",\"sched\"]=2\n",
    "        if not key==\"mass\":\n",
    "            \n",
    "            ax[0].plot(df[key],df[\"val_w1m\"],'o',alpha=0.2)\n",
    "        else:\n",
    "            sel1=(df[key]==True)&(df[\"quantile\"]==True)\n",
    "            sel2=(df[key]==True)&(df[\"quantile\"]==False)\n",
    "            ax[0].plot(df[sel1][key],df[sel1][\"val_w1m\"],'o',alpha=0.2,label=\"quantile\")\n",
    "            ax[0].plot(df[sel2][key],df[sel2][\"val_w1m\"],'o',alpha=0.2,label=\"not quantile\")\n",
    "            ax[0].legend()\n",
    "        plt.ylim(0.8,30)\n",
    "        # plt.xlim(8,20)\n",
    "        ax[0].set_yscale(\"log\")\n",
    "        if key in [\"lr_g\",\"lr_d\"]:\n",
    "            ax[0].set_xscale(\"log\")\n",
    "            plt.suptitle(\"Learning Rate\")\n",
    "        ax[0].set_xlabel(key)\n",
    "        ax[0].set_ylabel(\"w1m\")\n",
    "        if key==\"opt\":\n",
    "            ax[0].set_xticks([0,1,2])\n",
    "            ax[0].set_xticklabels([\"Adam\",\"AdamW\",\"RMSprop\"])\n",
    "        if key==\"wgan\":\n",
    "            ax[0].set_xticks([0,1])\n",
    "            ax[0].set_xticklabels([False,True])\n",
    "            ax[1].set_xticks([0,1])\n",
    "            ax[1].set_xticklabels([False,True])\n",
    "        if key==\"sched\":\n",
    "            ax[0].set_xticks([1,2])\n",
    "            ax[0].set_xticklabels([\n",
    "                \"cosine\",\"cosine2\"])\n",
    "        if key==\"sched\":\n",
    "            ax[1].set_xticks([1,2])\n",
    "            ax[1].set_xticklabels([\n",
    "                \"cosine\",\"cosine2\"])\n",
    "        plt.xlabel(key)\n",
    "        plt.ylabel(\"fpnd\")\n",
    "        ax[1].plot(df[key],df[\"val_fpnd\"],'o',alpha=0.2)\n",
    "        # plt.ylim(0.5,100)\n",
    "        # plt.ylim(0.1,2)\n",
    "        if key==\"opt\":\n",
    "            ax[1].set_xticks([0,1,2])\n",
    "            ax[1].set_xticklabels([\"Adam\",\"SGD\",\"RMSprop\"])\n",
    "        if key==\"wgan\":\n",
    "            ax[1].set_xticks([0,1])\n",
    "            ax[1].set_xticklabels([False,True])\n",
    "        if key==\"sched\":\n",
    "            ax[0].set_xticks([0,1,2])\n",
    "            ax[0].set_xticklabels([\"None\",\"cosine\",\"cosine2\"])\n",
    "        if key in [\"lr_g\",\"lr_d\"]:\n",
    "            plt.xscale(\"log\")\n",
    "        # plt.xlim(8,20)\n",
    "        # plt.xscale()\n",
    "        if key==\"opt\":\n",
    "            plt.suptitle(\"Optimizer\",fontweight='bold')\n",
    "        if key==\"wgan\":\n",
    "            plt.suptitle(\"WGAN\",fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        if key==\"mass\":\n",
    "            plt.suptitle(\"Mass as Discriminator Input\",fontweight='bold')\n",
    "        if key==\"lr_g\":\n",
    "            plt.suptitle(\"Learning Rate\",fontweight='bold')\n",
    "        if key==\"hidden\":\n",
    "            plt.suptitle(\"Hidden Nodes\",fontweight='bold')\n",
    "        if key==\"num_layers\":\n",
    "            plt.suptitle(\"Number Layers\",fontweight='bold')\n",
    "        if key==\"heads\":\n",
    "            plt.suptitle(\"Number Heads\",fontweight='bold')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        plt.yscale(\"log\")\n",
    "        plt.show()\n",
    "        # plt.ylim(0.1,5)\n",
    "    except:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ea3ec-5c98-4228-8a69-d1eb5c845a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f4fbd-daae-4697-a5ab-25140eca95c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetnet",
   "language": "python",
   "name": "jetnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
