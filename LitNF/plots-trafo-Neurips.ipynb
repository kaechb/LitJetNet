{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148e9d34-e26d-4a67-acf8-48081ff27e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "import torch\n",
    "from jetnet_dataloader import JetNetDataloader\n",
    "from lit_nf import TransGan\n",
    "from plotting import *\n",
    "import pandas as pd\n",
    "from jetnet.evaluation import w1p, w1efp, w1m, cov_mmd,fpnd\n",
    "from jetnet.datasets import JetNet\n",
    "from main import train\n",
    "pd.set_option(\"display.max_colwidth\",200)\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import torch\n",
    "import numpy as np\n",
    "import hist\n",
    "from hist import Hist\n",
    "import traceback\n",
    "from helpers import mass\n",
    "import pandas as pd\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "class plotting_paper():\n",
    "    '''This is a class that takes care of  plotting steps in the script,\n",
    "        It is initialized with the following arguments:\n",
    "        true=the simulated data, note that it needs to be scaled\n",
    "        gen= Generated data , needs to be scaled\n",
    "        step=The current step of the training, this is need for tensorboard\n",
    "        model=the model that is trained, a bit of an overkill as it is only used to access the losses\n",
    "        config=the config used for training\n",
    "        logger=The logger used for tensorboard logging'''\n",
    "    def __init__(self,true,gen,config,step,p,model=None,logger=None,weight=1):\n",
    "        self.config=model.config\n",
    "        self.n_dim=self.config[\"n_dim\"]\n",
    "        self.gen=gen\n",
    "        self.test_set=true\n",
    "        self.step=step\n",
    "        self.model=model\n",
    "        self.p=p\n",
    "\n",
    "        self.weight=weight\n",
    "        if logger is not None:\n",
    "            self.summary=logger\n",
    "    def plot_mass_only(self,m,m_t,bins=15):\n",
    "        fig,ax=plt.subplots(2,1,gridspec_kw={'height_ratios': [3, 1]},figsize=(6,8))\n",
    "        a=min(np.quantile(m_t,0.001),np.quantile(m,0.001))\n",
    "        b=max(np.quantile(m_t,0.999),np.quantile(m,0.999))\n",
    "        a=np.quantile(m_t,0.001)\n",
    "        b=np.quantile(m_t,0.999)\n",
    "        h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "        h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "        bins = h.axes[0].edges\n",
    "        h.fill(m)#,weight=1/self.weight)\n",
    "        h2.fill(m_t)\n",
    "            \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "\n",
    "        main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "            h2,\n",
    "            ax_dict={\"main_ax\":ax[0],\"ratio_ax\":ax[1]},\n",
    "            rp_ylabel=r\"Ratio\",\n",
    "            rp_num_label=\"Flow Generated\",\n",
    "            rp_denom_label=\"MC Simulatied\",\n",
    "            rp_uncert_draw_type=\"line\",  # line or bar\n",
    "        )\n",
    "        ax[0].set_xlabel(\"\")\n",
    "#                 if quantile and v==\"m\" and plot_vline:\n",
    "#                     ax[0,k].hist(m[m_t<np.quantile(m_t,0.1)],histtype='step',bins=bins,alpha=1,color=\"red\",label=\"10% quantile gen\",hatch=\"/\")\n",
    "#                     ax[0,k].vlines(np.quantile(m_t,0.1),0,np.max(h[:]),color=\"red\",label='10% quantile train')\n",
    "\n",
    "        ax[1].set_ylim(0.25,2)\n",
    "        ax[0].set_xlim(a,b)\n",
    "        ax[1].set_xlabel(\"$m_T$\",fontweight=\"bold\")\n",
    "        ax[1].set_xlim(a,b)\n",
    "        ax[0].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "        ax[1].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "  \n",
    "     \n",
    "#             print(\"added figure\")\n",
    "#             self.summary.close()\n",
    "\n",
    "        plt.savefig(\"{}_mass\".format(self.p))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_marginals(self,ith=None,save=False,title=None):\n",
    "        #This plots the marginal distribution for simulation and generation\n",
    "        #Note that this is the data the model sees during training as input to model in the NF\n",
    "        #This is the distribution of one of [eta,phi,pt] of one particle of the n particles per jet: for example the pt of the 3rd particle\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        \n",
    "        plt.switch_backend('agg')\n",
    "        name,label=[\"eta\",\"phi\",\"pt\"],['${\\eta}^{rel}_{7}$',\"${\\phi}^{rel}_{7}$\",\"${p_T}^{rel}_{7}$\"]\n",
    "        fig,ax=plt.subplots(2,3,gridspec_kw={'height_ratios': [3, 1]},figsize=(18,6))\n",
    "        particles=range(self.n_dim) if not ith else [3*ith,3*ith+1,3*ith+2]\n",
    "        plt.suptitle(title,fontweight=\"bold\")\n",
    "        k=0\n",
    "        for i in particles:\n",
    "            if ith:\n",
    "                ax_temp=ax[:,k]\n",
    "            else:\n",
    "                fig,ax_temp=plt.subplots(2,1)\n",
    "            a=np.quantile(self.test_set[:,i].numpy(),0)\n",
    "            b=np.quantile(self.test_set[:,i].numpy(),1)\n",
    "\n",
    "            h=hist.Hist(hist.axis.Regular(15,a,b,label=label[i%3],underflow=False,overflow=False))\n",
    "            h2=hist.Hist(hist.axis.Regular(15,a,b,label=label[i%3],underflow=False,overflow=False))\n",
    "            h.fill(self.gen[:,i].numpy())\n",
    "            h2.fill(self.test_set[:,i].numpy())\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0,k] )\n",
    "       \n",
    "            main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "                h2,\n",
    "                ax_dict={\"main_ax\":ax_temp[0],\"ratio_ax\":ax_temp[1]},\n",
    "                rp_ylabel=r\"Ratio\",\n",
    "#                 rp_xlabel=label[i%3],\n",
    "                rp_num_label=\"Flow Generated\",\n",
    "                rp_denom_label=\"MC Simulated\",\n",
    "                rp_uncert_draw_type=\"line\",  # line or bar\n",
    "            )\n",
    "            \n",
    "            \n",
    "            ax_temp[0].set_xlabel(\"\")\n",
    "            ax_temp[1].set_ylim(0.25,2)\n",
    "            ax_temp[0].set_xlim(a,b)\n",
    "            ax_temp[1].set_xlim(a,b)\n",
    "            ax_temp[1].set_xlabel(label[i%3])\n",
    "            ax_temp[0].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "            ax_temp[1].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "            \n",
    "            \n",
    "            #plt.tight_layout(pad=2)\n",
    "            k+=1\n",
    "        if save:\n",
    "            self.summary.add_figure(\"jet{}_{}\".format(i//3+1,name[i%3]),fig,global_step=self.step)\n",
    "            self.summary.close()\n",
    "        else:\n",
    "            plt.savefig(\"{}_7thpart\".format(self.p))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def plot_2d(self,save=False):\n",
    "        #This creates a 2D histogram of the inclusive distribution for all 3 feature combinations\n",
    "        #Inclusive means that is the distribution of pt of all particles per jet and sample\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        data=self.test_set[:,:self.n_dim].reshape(-1,3).numpy()\n",
    "        gen=self.gen[:,:self.n_dim].reshape(-1,3).numpy()\n",
    "        labels=[r\"$\\eta^{rel}$\",r\"$\\phi^{rel}_7$\",r\"$p_T^{rel}$\"]\n",
    "        names=[\"eta\",\"phi\",\"pt\"]\n",
    "        for index in [[0,1],[0,2],[1,2]]:\n",
    "            \n",
    "            fig,ax=plt.subplots(ncols=2,figsize=(16, 8))\n",
    "            _,x,y,_=ax[0].hist2d(data[:,index[0]],data[:,index[1]],bins=30)\n",
    "            #rebin to only take 5% to 95.0% of signal dis\n",
    "            a=np.quantile(x,0.05)\n",
    "            b=np.quantile(x,0.95)\n",
    "            x=np.linspace(a,b,len(x))\n",
    "            a=np.quantile(y,0.05)\n",
    "            b=np.quantile(y,0.95)\n",
    "            y=np.linspace(a,b,len(y))\n",
    "            if index[1]==2:\n",
    "                y=np.abs(y)+0.00001\n",
    "                y = np.logspace(np.log(y[0]),np.log(y[-1]),len(y))\n",
    "            ax[0].hist2d(data[:,index[0]],data[:,index[1]],bins=[x,y])\n",
    "            data[:,index[0]]=np.abs(data[:,index[0]])+0.00001\n",
    "            ax[1].hist2d(gen[:,index[0]],gen[:,index[1]],bins=[x,y])\n",
    "        \n",
    "        \n",
    "            plt.tight_layout(pad=2)\n",
    "            ax[0].set_xlabel( labels[index[0]],fontweight=\"bold\")\n",
    "            ax[0].set_ylabel( labels[index[1]],fontweight=\"bold\")\n",
    "            \n",
    "            ax[0].set_title(\"MC Simulated\")\n",
    "            ax[1].set_xlabel( labels[index[0]],fontweight=\"bold\")\n",
    "            ax[1].set_ylabel( labels[index[1]],fontweight=\"bold\")\n",
    "            \n",
    "            ax[1].set_title(\"Flow Generated\")\n",
    "           \n",
    "            if save:\n",
    "                self.summary.add_figure(\"2d{}-{}\".format(names[index[0]],names[index[1]]),fig,global_step=self.step)\n",
    "                \n",
    "                # self.summary.close()\n",
    "            else:\n",
    "                plt.savefig(\"{}_2dcorr{}{}\".format(self.p,names[index[0]],names[index[0]]))\n",
    "                plt.show()\n",
    "                \n",
    " \n",
    "        \n",
    "    def oversample(self,m,m_t,weight,save=False,quantile=False,bins=15,plot_vline=False,title=\"\"):\n",
    "        #This creates a histogram of the inclusive distributions and calculates the mass of each jet\n",
    "        #and creates a histogram of that\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        #if quantile, this also creates a histogram of a subsample of the generated data, \n",
    "        # where the mass used to condition the flow is in the first 10% percentile of the simulated mass dist\n",
    "        i=0\n",
    "        k=0\n",
    "        fig,ax=plt.subplots(2,4,gridspec_kw={'height_ratios': [3, 1]},figsize=(20,5))\n",
    "        plt.suptitle(title,fontweight=\"bold\")\n",
    "        for v,name in zip([\"eta\",\"phi\",\"pt\",\"m\"],[r\"$\\eta^{rel}$\",r\"$\\phi^{rel}$\",r\"$p_T^{rel}$\",r\"$m^{rel}$\"]):\n",
    "            \n",
    "            if v!=\"m\":\n",
    "                a=min(np.quantile(self.gen[:,i],0.001),np.quantile(self.test_set[:,i],0.001))\n",
    "                b=max(np.quantile(self.gen[:,i],0.999),np.quantile(self.test_set[:,i],0.999))     \n",
    "                \n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h.fill(self.gen[:,i],weight=1/weight)\n",
    "                h2.fill(self.test_set[:,i])\n",
    "                i+=1\n",
    "            else:\n",
    "                a=min(np.quantile(m_t,0.001),np.quantile(m,0.001))\n",
    "                b=max(np.quantile(m_t,0.999),np.quantile(m,0.999))\n",
    "                a=np.quantile(m_t,0.001)\n",
    "                b=np.quantile(m_t,0.999)\n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                bins = h.axes[0].edges\n",
    "                h.fill(m,weight=1/weight)#,weight=1/self.weight)\n",
    "                h2.fill(m_t)\n",
    "            \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            try:\n",
    "                main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "                    h2,\n",
    "                    ax_dict={\"main_ax\":ax[0,k],\"ratio_ax\":ax[1,k]},\n",
    "                    rp_ylabel=r\"Ratio\",\n",
    "                    rp_num_label=\"Flow Generated\",\n",
    "                    rp_denom_label=\"MC Simulatied\",\n",
    "                    rp_uncert_draw_type=\"line\",  # line or bar\n",
    "                )\n",
    "                ax[0,k].set_xlabel(\"\")\n",
    "#                 if quantile and v==\"m\" and plot_vline:\n",
    "#                     ax[0,k].hist(m[m_t<np.quantile(m_t,0.1)],histtype='step',bins=bins,alpha=1,color=\"red\",label=\"10% quantile gen\",hatch=\"/\")\n",
    "#                     ax[0,k].vlines(np.quantile(m_t,0.1),0,np.max(h[:]),color=\"red\",label='10% quantile train')\n",
    "                    \n",
    "                ax[1,k].set_ylim(0.25,2)\n",
    "                ax[0,k].set_xlim(a,b)\n",
    "                ax[1,k].set_xlabel(name,fontweight=\"bold\")\n",
    "                ax[1,k].set_xlim(a,b)\n",
    "                ax[0,k].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "                ax[1,k].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "                \n",
    "#                 if plot_vline:\n",
    "#                        ax[0,k].legend([\"Generated\",\"Training\",\"10% quantile Gen\",\"10% quantile Sim\"] )\n",
    "#                 else:\n",
    "#                       ax[0,k].legend([\"Flow Generated\",\"MC Simulated\"] )\n",
    "            except:\n",
    "                print(\"mass plot failed reverting to simple plot mass bins\")\n",
    "                plt.close()\n",
    "                plt.figure()\n",
    "                _,b,_=plt.hist(m_t,15,label=\"MC Simulated\",alpha=0.5)\n",
    "                plt.hist(m,b,label=\"Flow Generated\",alpha=0.5)\n",
    "                plt.legend()  \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            \n",
    "#             plt.xlabel(name)\n",
    "            plt.tight_layout(pad=1)\n",
    "            k+=1\n",
    "        if save:\n",
    "            if v!=\"m\":\n",
    "                 self.summary.add_figure(\"inclusive\"+v,fig,self.step)\n",
    "            else:\n",
    "                self.summary.add_figure(\"jet_mass\",fig,self.step)\n",
    "#             print(\"added figure\")\n",
    "#             self.summary.close()\n",
    "        else:\n",
    "            plt.savefig(\"{}_oversample_{}\".format(self.p,v))\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "    def plot_mass(self,m,m_t,save=False,quantile=False,bins=15,plot_vline=False,title=\"\"):\n",
    "        #This creates a histogram of the inclusive distributions and calculates the mass of each jet\n",
    "        #and creates a histogram of that\n",
    "        #if save, the histograms are logged to tensorboard otherwise they are shown\n",
    "        #if quantile, this also creates a histogram of a subsample of the generated data, \n",
    "        # where the mass used to condition the flow is in the first 10% percentile of the simulated mass dist\n",
    "        i=0\n",
    "        k=0\n",
    "        fig,ax=plt.subplots(2,4,gridspec_kw={'height_ratios': [3, 1]},figsize=(24,6))\n",
    "        plt.suptitle(title,fontweight=\"bold\")\n",
    "        for v,name in zip([\"eta\",\"phi\",\"pt\",\"m\"],[r\"$\\eta^{rel}$\",r\"$\\phi^{rel}$\",r\"$p_T^{rel}$\",r\"$m^{rel}$\"]):\n",
    "            \n",
    "            if v!=\"m\":\n",
    "                a=min(np.quantile(self.gen[:,i],0.001),np.quantile(self.test_set[:,i],0.001))\n",
    "                b=max(np.quantile(self.gen[:,i],0.999),np.quantile(self.test_set[:,i],0.999))     \n",
    "                \n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h.fill(self.gen[:,i])\n",
    "                h2.fill(self.test_set[:,i])\n",
    "                i+=1\n",
    "            else:\n",
    "                a=min(np.quantile(m_t,0.001),np.quantile(m,0.001))\n",
    "                b=max(np.quantile(m_t,0.999),np.quantile(m,0.999))\n",
    "                a=np.quantile(m_t,0.001)\n",
    "                b=np.quantile(m_t,0.999)\n",
    "                h=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                h2=hist.Hist(hist.axis.Regular(bins,a,b))\n",
    "                bins = h.axes[0].edges\n",
    "                h.fill(m)#,weight=1/self.weight)\n",
    "                h2.fill(m_t)\n",
    "            \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            try:\n",
    "                main_ax_artists, sublot_ax_arists = h.plot_ratio(\n",
    "                    h2,\n",
    "                    ax_dict={\"main_ax\":ax[0,k],\"ratio_ax\":ax[1,k]},\n",
    "                    rp_ylabel=r\"Ratio\",\n",
    "                    rp_num_label=\"Flow Generated\",\n",
    "                    rp_denom_label=\"MC Simulatied\",\n",
    "                    rp_uncert_draw_type=\"line\",  # line or bar\n",
    "                )\n",
    "                ax[0,k].set_xlabel(\"\")\n",
    "#                 if quantile and v==\"m\" and plot_vline:\n",
    "#                     ax[0,k].hist(m[m_t<np.quantile(m_t,0.1)],histtype='step',bins=bins,alpha=1,color=\"red\",label=\"10% quantile gen\",hatch=\"/\")\n",
    "#                     ax[0,k].vlines(np.quantile(m_t,0.1),0,np.max(h[:]),color=\"red\",label='10% quantile train')\n",
    "                    \n",
    "                ax[1,k].set_ylim(0.25,2)\n",
    "                ax[0,k].set_xlim(a,b)\n",
    "                ax[1,k].set_xlabel(name,fontweight=\"bold\")\n",
    "                ax[1,k].set_xlim(a,b)\n",
    "                ax[0,k].set_ylabel(\"Counts\",fontweight=\"bold\" )\n",
    "                ax[1,k].set_ylabel(\"Ratio\",fontweight=\"bold\")\n",
    "                ax[0,k].legend(loc=\"upper left\")  \n",
    "#                 if plot_vline:\n",
    "#                        ax[0,k].legend([\"Generated\",\"Training\",\"10% quantile Gen\",\"10% quantile Sim\"] )\n",
    "#                 else:\n",
    "#                       ax[0,k].legend([\"Flow Generated\",\"MC Simulated\"] )\n",
    "            except:\n",
    "                print(\"mass plot failed reverting to simple plot mass bins\")\n",
    "                plt.close()\n",
    "                plt.figure()\n",
    "                _,b,_=plt.hist(m_t,15,label=\"MC Simulated\",alpha=0.5)\n",
    "                plt.hist(m,b,label=\"Flow Generated\",alpha=0.5)\n",
    "                plt.legend(loc=\"upper left\")  \n",
    "            #hep.cms.label(data=False,lumi=None ,year=None,rlabel=\"\",llabel=\"Private Work\",ax=ax[0] )\n",
    "            \n",
    "#             plt.xlabel(name)\n",
    "            plt.tight_layout(pad=1)\n",
    "            \n",
    "\n",
    "            k+=1\n",
    "        if save:\n",
    "            if v!=\"m\":\n",
    "                 self.summary.add_figure(\"inclusive\"+v,fig,self.step)\n",
    "            else:\n",
    "                self.summary.add_figure(\"jet_mass\",fig,self.step)\n",
    "#             print(\"added figure\")\n",
    "#             self.summary.close()\n",
    "        else:\n",
    "            plt.savefig(\"{}_inclusive_{}\".format(self.p,v))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def losses(self,save=False):\n",
    "        '''This plots the different losses vs epochs'''\n",
    "        fig=plt.figure()\n",
    "        hep.cms.label(\"Private Work\",data=None,lumi=None,year=None)\n",
    "        plt.xlabel('step')\n",
    "        plt.ylabel('loss')\n",
    "        ln1=plt.plot(self.model.logprobs,label='log$(p_{gauss}(x_{data}))$')\n",
    "        if \"calc_massloss\" in self.config.keys() and self.config[\"calc_massloss\"]:\n",
    "            plt.twinx()\n",
    "            ln2=plt.plot(self.model.mlosses,label=r'mass mse $\\times$ {}'.format(self.config[\"lambda\"]),color='orange')\n",
    "            plt.ylabel(\"MSE\")\n",
    "            plt.yscale(\"log\")\n",
    "            ln1+=ln2\n",
    "        labs=[l.get_label() for l in ln1]\n",
    "        plt.legend(ln1,labs)\n",
    "        plt.tight_layout(pad=2)\n",
    "        if save:\n",
    "            self.summary.add_figure(\"losses\",fig,self.step)\n",
    "#             self.summary.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "   \n",
    "\n",
    "    def plot_correlations(self,save=True):\n",
    "        #Plots correlations between all particles for i=0 eta,i=1 phi,i=2 pt\n",
    "        self.plot_corr(i=0,save=save)\n",
    "        self.plot_corr(i=1,save=save)\n",
    "        self.plot_corr(i=2,save=save)\n",
    "\n",
    "    def plot_corr(self,i=0,names=[\"$\\eta^{rel}$\",\"$\\phi^{rel}$\",\"$p_T$\"],save=True):\n",
    "        if i==2:\n",
    "            c=1\n",
    "        else:\n",
    "            c=1\n",
    "        df_g=pd.DataFrame(self.gen.reshape(-1,90).detach().numpy()[:,range(i,90,3)])\n",
    "        df_h=pd.DataFrame(self.test_set.reshape(-1,90).detach().numpy()[:,range(i,90,3)])\n",
    "        fig,ax=plt.subplots(ncols=2,figsize=(20,10))\n",
    "        corr_g = ax[0].matshow(df_g.corr())\n",
    "        corr_g.set_clim(-c,c)\n",
    "        divider = make_axes_locatable(ax[0])\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        cbar=fig.colorbar(corr_g,cax=cax)\n",
    "        corr_h = ax[1].matshow(df_h.corr())\n",
    "        corr_h.set_clim(-c,c)\n",
    "        divider = make_axes_locatable(ax[1])\n",
    "        cax2 = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        cbar=fig.colorbar(corr_h,cax=cax2)\n",
    "        plt.suptitle(\"{} Correlation between Particles\".format(names[i]),fontweight=\"bold\")\n",
    "        ax[0].set_title(\"Flow Generated\",fontweight=\"bold\")\n",
    "        ax[1].set_title(\"MC Simulated\",fontweight=\"bold\")\n",
    "        ax[0].set_xlabel(\"Particles\",fontweight=\"bold\")\n",
    "        ax[0].set_ylabel(\"Particles\",fontweight=\"bold\")\n",
    "        ax[1].set_xlabel(\"Particles\",fontweight=\"bold\")\n",
    "        ax[1].set_ylabel(\"Particles\",fontweight=\"bold\")\n",
    "        title=[\"corr_eta\",\"corr_phi\",\"corr_pt\"]\n",
    "        if save:\n",
    "                \n",
    "                self.summary.add_figure(title[i],fig,self.step)    \n",
    "    #             self.summary.close()\n",
    "        else:\n",
    "                plt.savefig(\"{}_{}\".format(self.p,title[i]))\n",
    "                plt.show()\n",
    "\n",
    "    def var_part(self,true,gen,true_n,gen_n,m_true,m_gen,form=2,save=True):\n",
    "        labels=[\"$\\eta^{rel}$\",\"$\\phi^{rel}$\",\"$p^{rel}_T$\",\"$m^{rel}$\"]\n",
    "        names=[\"eta\",\"phi\",\"pt\",\"m\"]\n",
    "        n,counts=torch.unique(true_n,return_counts=True)\n",
    "        for j in range(4):\n",
    "            fig,ax=plt.subplots(ncols=2,nrows=2,figsize=(15,15))\n",
    "\n",
    "            k=-1\n",
    "            ntemp=n[-form**2:]\n",
    "\n",
    "            \n",
    "            for i in list(ntemp)[::-1]: \n",
    "                k+=1\n",
    "                i=int(i)\n",
    "\n",
    "                if names[j]!=\"m\":\n",
    "                    a=np.quantile(self.test_set[true_n.reshape(-1)==i,:].reshape(-1,3)[:,j],0.001)\n",
    "                    b=np.quantile(self.test_set[true_n.reshape(-1)==i,:].reshape(-1,3)[:,j],0.999)    \n",
    "                    h=hist.Hist(hist.axis.Regular(15,a,b))\n",
    "                    h2=hist.Hist(hist.axis.Regular(15,a,b))\n",
    "                    bins = h.axes[0].edges\n",
    "\n",
    "                    ax[k//form,k%form].legend()\n",
    "                    h.fill(self.gen[gen_n.reshape(-1)==i,:].reshape(-1,3)[:,j])\n",
    "                    h2.fill(self.test_set[true_n.reshape(-1)==i,:].reshape(-1,3)[:,j])\n",
    "                    \n",
    "                else:\n",
    "                    a=np.quantile(m_true[true_n.reshape(-1)==i],0.001)\n",
    "                    b=np.quantile(m_gen[gen_n.reshape(-1)==i],0.999)\n",
    "  \n",
    "                    h=hist.Hist(hist.axis.Regular(15,a,b,label=labels[j]))\n",
    "                    h2=hist.Hist(hist.axis.Regular(15,a,b,label=labels[j]))\n",
    "                    bins = h.axes[0].edges\n",
    "                    h.fill(m_gen[gen_n.reshape(-1)==i])\n",
    "                    h2.fill(m_true[true_n.reshape(-1)==i])\n",
    "                    \n",
    "\n",
    "                h.plot1d(    ax=ax[k//2,k%2],label=\"Flow Simulated\")  # line or bar)\n",
    "                h2.plot1d(    ax=ax[k//2,k%2],label=\"MC Generated\")  # line or bar)\n",
    "                ax[k//2,k%2].set_title(\"{} Distribution for jets with {} particles\".format(labels[j],i))\n",
    "\n",
    "                ax[k//2,k%2].set_xlabel(labels[j])\n",
    "                ax[k//2,k%2].set_ylabel(\"Counts\",fontweight=\"bold\")\n",
    "                ax[k//2,k%2].set_xlim(a,b)\n",
    "                ax[k//2,k%2].legend()\n",
    "                #plt.tight_layout(pad=2)\n",
    "\n",
    "            if save:\n",
    "                self.summary.add_figure(\"jet{}_{}\".format(i//3+1,names[i%3]),fig,global_step=self.step)\n",
    "                self.summary.close()\n",
    "            else:\n",
    "                plt.savefig(\"jet{}_{}\".format(self.p,i//3+1,names[j]))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0d55ce8-cd67-4aa7-a023-affac827af19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.585348e+06, 6.648210e+05, 2.325090e+05, 1.081130e+05,\n",
       "        5.724600e+04, 3.240000e+04, 2.002200e+04, 1.222400e+04,\n",
       "        6.959000e+03, 5.170000e+03, 3.572000e+03, 2.453000e+03,\n",
       "        1.692000e+03, 1.282000e+03, 8.630000e+02, 6.010000e+02,\n",
       "        4.640000e+02, 3.590000e+02, 2.150000e+02, 1.650000e+02,\n",
       "        1.340000e+02, 7.800000e+01, 4.400000e+01, 3.800000e+01,\n",
       "        3.300000e+01, 1.000000e+01, 4.000000e+00, 6.000000e+00,\n",
       "        1.000000e+00, 4.000000e+00]),\n",
       " array([0.        , 0.02850437, 0.05700875, 0.08551312, 0.11401749,\n",
       "        0.14252187, 0.17102624, 0.19953062, 0.22803499, 0.25653937,\n",
       "        0.28504375, 0.31354812, 0.3420525 , 0.37055686, 0.39906123,\n",
       "        0.4275656 , 0.45606998, 0.48457435, 0.51307875, 0.5415831 ,\n",
       "        0.5700875 , 0.59859186, 0.62709624, 0.6556006 , 0.684105  ,\n",
       "        0.71260935, 0.7411137 , 0.7696181 , 0.79812247, 0.82662684,\n",
       "        0.8551312 ], dtype=float32),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df.data.reshape(-1,4).numpy()[:,2],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d3ab045-ef47-48fc-a0a7-d548f27db003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124561, 30, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jetnet\n",
    "df=jetnet.datasets.JetNet(\"t\",normalize=False)\n",
    "df.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eeec8f7-62f4-4d96-877e-32bb9f53b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {'autoreg': False, 'context_features': 0, 'network_layers': 3, 'network_layers_nf': 2, 'network_nodes_nf': 256, 'batch_size': 1024, 'coupling_layers': 15, 'lr': 0.001, 'batchnorm': False, 'bins': 5, 'tail_bound': 6, 'limit': 150000, 'n_dim': 3, 'dropout': 0.2, 'canonical': False, 'max_steps': 100000, 'lambda': 1, 'name': 'Transflow_best', 'disc': False, 'variable': 1, 'parton': 't', 'wgan': False, 'corr': True, 'num_layers': 4, 'freq': 6, 'n_part': 30, 'fc': False, 'hidden': 500, 'heads': 4, 'l_dim': 100, 'lr_g': 0.0004327405312571664, 'lr_d': 0.0004327405312571664, 'lr_nf': 0.000722, 'sched': 'cosine2', 'opt': 'RMSprop', 'max_epochs': 3200, 'mass': True, 'no_hidden': False, 'clf': True, 'val_check': 50, 'frac_pretrain': 80, 'seed': 69, 'quantile': False}, 'num_batches': 112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/beegfs/desy/user/kaechben/.conda/envs/jetnet/lib/python3.8/site-packages/torch/nn/init.py:403: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/kaechben/JetNet_NF/LitJetNet/LitNF/lit_nf.py:270: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  nn.init.xavier_normal(p)\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "best_hparam=\"/beegfs/desy/user/kaechben/Transflow_best/lightning_logs/version_72/hparams.yaml\"\n",
    "best_hparam=\"/beegfs/desy/user/kaechben/Transflow_best/lightning_logs/version_136/hparams.yaml\"\n",
    "\n",
    "with open(best_hparam, 'r') as stream:\n",
    "        config=yaml.load(stream,Loader=yaml.Loader)\n",
    "        print(config)\n",
    "        config=config[\"config\"]\n",
    "data_module = JetNetDataloader(config,) #this loads the data\n",
    "data_module.setup(\"train\")\n",
    "# data=data_module.scaler.inverse_transform(data_module.data[:,:90]).reshape(-1,30,3)\n",
    "model = TransGan(config,data_module.num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78435b12-78a4-4ada-aa8e-351284ff58eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1909634580456725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model=\"/beegfs/desy/user/kaechben/Transflow_best/epoch=1749-val_fpnd=0.08-val_w1m=0.0008.ckpt\"\n",
    "best_model=\"/beegfs/desy/user/kaechben/Transflow_best/epoch=2399-val_fpnd=0.16-val_w1m=0.0007.ckpt\"\n",
    "batch=data_module.test_set\n",
    "mask = batch[:, 90:].cpu().bool()\n",
    "batch = batch[:, :90].cpu()\n",
    "\n",
    "model=model.load_from_checkpoint(best_model)\n",
    "model.load_datamodule(data_module)\n",
    "\n",
    "mask_test = model.sample_n(mask).bool()\n",
    "# mask_test=mask\n",
    "\n",
    "model.flow.train()\n",
    "model.dis_net.train()\n",
    "model.gen_net.train()\n",
    "model.data_module.scaler.to(\"cpu\")\n",
    "batch = batch.to(\"cpu\")\n",
    "model.flow = model.flow.to(\"cpu\")\n",
    "model.dis_net = model.dis_net.cpu()\n",
    "model.gen_net = model.gen_net.cpu()\n",
    "with torch.no_grad():\n",
    "#for some wierd reason its better with mask==None???\n",
    "    gen, true, z, fake_scaled, true_scaled, z_scaled = model.sampleandscale(batch, mask=mask_test,scale=True)\n",
    "    fake_scaled=fake_scaled*(~mask_test).reshape(-1,30,1)\n",
    "    true_scaled=true_scaled*mask.reshape(-1,30,1)\n",
    "    if model.config[\"mass\"]:\n",
    "        m_t = mass(batch.reshape(len(batch), model.n_part * model.n_dim), model.config[\"canonical\"])\n",
    "        m_f = mass(gen.reshape(len(batch), model.n_part * model.n_dim), model.config[\"canonical\"])\n",
    "\n",
    "    \n",
    "    # Reverse Standard Scaling (this has nothing to do with flows, it is a standard preprocessing step)\n",
    "    \n",
    "    true_scaled, fake_scaled, z_scaled = (true_scaled.reshape(-1, 90), fake_scaled.reshape(-1, 90), z_scaled.reshape(-1, 90))\n",
    "    for i in range(30):\n",
    "        i = 2 + 3 * i\n",
    "        z_scaled[z_scaled[:,i]<0,i]=0\n",
    "        fake_scaled[fake_scaled[:, i] < 0, i] = 0\n",
    "        true_scaled[true_scaled[:, i] < 0, i] = 0\n",
    "    # Some metrics we track\n",
    "    cov, mmd = cov_mmd(fake_scaled.reshape(-1, model.n_part, model.n_dim), true_scaled.reshape(-1, model.n_part, model.n_dim), use_tqdm=False)\n",
    "    try:\n",
    "        fpndv = fpnd(fake_scaled.reshape(-1, model.n_part, model.n_dim).numpy(), use_tqdm=False, jet_type=model.config[\"parton\"])\n",
    "        print(fpndv)\n",
    "    except:\n",
    "        fpndv = 1000\n",
    "    w1m_ = w1m(fake_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))\n",
    "    w1p_ = w1p(fake_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))\n",
    "    w1efp_ = w1efp(fake_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86d4e3e-cfa7-4f98-b176-9922ad7943ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   0., 679.,   0.,   0.,   0.,   0.]),\n",
       " array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(fake_scaled[mask_test[:,-1],-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad9d8850-2bf7-409c-8885-5d96219314f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.0010172608145598532, 0.00018236029401274206),\n",
       " (1.876128479017114e-05, 1.462494957788929e-05),\n",
       " (0.0009600672754827626, 0.000345264524786217))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1m_,w1efp_,w1p_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916be0d-1bb3-4f9f-af51-c1a872a59942",
   "metadata": {},
   "source": [
    "# batch=torch.vstack((data_module.data[:,:90],batch))\n",
    "mask=torch.vstack((data_module.data[:,90:].bool(),mask))\n",
    "\n",
    "covz, mmdz = cov_mmd(z_scaled.reshape(-1, model.n_part, model.n_dim), true_scaled.reshape(-1, model.n_part, model.n_dim), use_tqdm=False)\n",
    "try:\n",
    "    fpndvz = fpnd(z_scaled.reshape(-1, model.n_part, model.n_dim).numpy(), use_tqdm=False, jet_type=model.config[\"parton\"])\n",
    "    print(fpndvz)\n",
    "except:\n",
    "    fpndv = 1000\n",
    "w1m_z = w1m(z_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))\n",
    "w1p_z = w1p(z_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))\n",
    "w1efp_z = w1efp(z_scaled.reshape(len(batch), model.n_part, model.n_dim), true_scaled.reshape(len(batch), model.n_part, model.n_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908620c4-1fc0-437a-84e3-d36bf722b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0010335198270001698, 0.00021850261132931535)\n"
     ]
    }
   ],
   "source": [
    "mask = batch[:, 90:].cpu()\n",
    "batch = batch[:, :90].cpu()\n",
    "mask_test=self.sample_n(mask)\n",
    "batch = batch.to(\"cpu\")\n",
    "model.flow.train()\n",
    "model.dis_net.train()\n",
    "model.gen_net.train()\n",
    "model.data_module.scaler.to(\"cpu\")\n",
    "batch = batch.to(\"cpu\")\n",
    "model.flow = model.flow.to(\"cpu\")\n",
    "model.dis_net = model.dis_net.cpu()\n",
    "model.gen_net = model.gen_net.cpu()\n",
    "\n",
    "with torch.no_grad():\n",
    "    gen, true, z, fake_scaled, true_scaled, z_scaled = model.sampleandscale(batch, mask=mask_test,scale=True)\n",
    "    if model.config[\"mass\"]:\n",
    "        m_t = mass(batch.reshape(len(batch), model.n_part * model.n_dim), model.config[\"canonical\"])\n",
    "        m_f = mass(gen.reshape(len(batch), model.n_part * model.n_dim), model.config[\"canonical\"])\n",
    "\n",
    "    \n",
    "true_scaled, fake_scaled, z_scaled = (true_scaled.reshape(-1, 90), fake_scaled.reshape(-1, 90), z_scaled.reshape(-1, 90))\n",
    "# Reverse Standard Scaling (this has nothing to do with flows, it is a standard preprocessing step)\n",
    "m_t = mass(\n",
    "    true_scaled[:, : self.n_dim * self.n_part].to(self.device),\n",
    "    self.config[\"canonical\"],\n",
    ").cpu()\n",
    "m_gen = mass(z_scaled[:, : self.n_dim * self.n_part], self.config[\"canonical\"]).cpu()\n",
    "m_c = mass(fake_scaled[:, : self.n_dim * self.n_part], self.config[\"canonical\"]).cpu()\n",
    "for i in range(30):\n",
    "    i = 2 + 3 * i\n",
    "    # gen[gen[:,i]<0,i]=0\n",
    "    fake_scaled[fake_scaled[:, i] < 0, i] = 0\n",
    "    true_scaled[true_scaled[:, i] < 0, i] = 0\n",
    "# Some metrics we track\n",
    "cov, mmd = cov_mmd(fake_scaled.reshape(-1, self.n_part, self.n_dim), true_scaled.reshape(-1, self.n_part, self.n_dim), use_tqdm=False)\n",
    "try:\n",
    "    fpndv = fpnd(fake_scaled.reshape(-1, self.n_part, self.n_dim).numpy(), use_tqdm=False, jet_type=self.config[\"parton\"])\n",
    "except:\n",
    "    fpndv = 1000\n",
    "w1m_ = w1m(fake_scaled.reshape(len(batch), self.n_part, self.n_dim), true_scaled.reshape(len(batch), self.n_part, self.n_dim))[0]\n",
    "w1p_ = w1p(fake_scaled.reshape(len(batch), self.n_part, self.n_dim), true_scaled.reshape(len(batch), self.n_part, self.n_dim))[0]\n",
    "w1efp_ = w1efp(fake_scaled.reshape(len(batch), self.n_part, self.n_dim), true_scaled.reshape(len(batch), self.n_part, self.n_dim))[0]\n",
    "self.metrics[\"val_fpnd\"].append(fpndv)\n",
    "self.metrics[\"val_logprob\"].append(logprob)\n",
    "self.metrics[\"val_mmd\"].append(mmd)\n",
    "self.metrics[\"val_cov\"].append(cov)\n",
    "self.metrics[\"val_w1p\"].append(w1p_)\n",
    "self.metrics[\"val_w1m\"].append(w1m_)\n",
    "self.metrics[\"val_w1efp\"].append(w1efp_)\n",
    "\n",
    "if (np.array([w1m_])[-4:] > 0.01).all() and self.current_epoch > 100 and not self.config[\"sched\"] == \"cosine2\":\n",
    "    print(\"no convergence, stop training\")\n",
    "    raise\n",
    "\n",
    "temp = {\n",
    "    \"val_logprob\": float(logprob.numpy()),\n",
    "    \"val_fpnd\": fpndv,\n",
    "    \"val_mmd\": mmd,\n",
    "    \"val_cov\": cov,\n",
    "    \"val_w1m\": w1m_,\n",
    "    \"val_w1efp\": w1efp_,\n",
    "    \"val_w1p\": w1p_,\n",
    "    \"step\": self.global_step,\n",
    "}\n",
    "print(\"epoch {}: \".format(self.current_epoch), temp)\n",
    "if self.hyperopt and self.global_step > 3:\n",
    "    try:\n",
    "        self._results(temp)\n",
    "    except:\n",
    "        print(\"error in results\")\n",
    "    summary = self._summary(temp)\n",
    "self.log(\"hp_metric\", self.metrics[\"val_w1m\"][-1], on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "self.log(\"val_w1m\", self.metrics[\"val_w1m\"][-1], on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "self.log(\"val_w1p\", self.metrics[\"val_w1p\"][-1], on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "self.log(\"val_w1efp\", self.metrics[\"val_w1efp\"][-1], on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "self.log(\"val_logprob\", logprob, prog_bar=True, logger=True)\n",
    "self.log(\"val_cov\", cov, prog_bar=True, logger=True, on_step=False, on_epoch=True)\n",
    "self.log(\"val_fpnd\", fpndv, prog_bar=True, logger=True, on_step=False, on_epoch=True)\n",
    "self.log(\"val_mmd\", mmd, prog_bar=True, logger=True, on_step=False, on_epoch=True)\n",
    "self.plot = plotting(\n",
    "    model=self,\n",
    "    gen=z_scaled,\n",
    "    gen_corr=fake_scaled,\n",
    "    true=true_scaled,\n",
    "    config=self.config,\n",
    "    step=self.global_step,\n",
    "    logger=self.logger.experiment,\n",
    ")\n",
    "try:\n",
    "    self.plot.plot_mass(m=m_gen.cpu().numpy(), m_t=m_t.cpu().numpy(), m_c=m_c.cpu().numpy(), save=True, bins=50, quantile=True, plot_vline=False)\n",
    "    # self.plot.plot_2d(save=True)\n",
    "#             self.plot.var_part(true=true[:,:self.n_dim],gen=gen_corr[:,:self.n_dim],true_n=n_true,gen_n=n_gen_corr,m_true=m_t,m_gen=m_test ,save=True)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "self.flow = self.flow.to(\"cuda\")\n",
    "self.gen_net = self.gen_net.to(\"cuda\")\n",
    "self.dis_net = self.dis_net.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61355d61-6876-422b-a24a-40af419d940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=torch.zeros((165000,30,4))\n",
    "file[:,:,:3]=fake_scaled.reshape(-1,30,3)\n",
    "file[:,:,3]=~mask_test\n",
    "torch.save(file,\"moritz.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28bec0b-e7e4-4083-a9d1-bf3e355098a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.586864471435547e-06\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "batch=data_module.test_set\n",
    "model=model.load_from_checkpoint(best_model)\n",
    "model.load_datamodule(data_module)\n",
    "mask = batch[:, 90:].cpu().bool()\n",
    "batch = batch[:, :90].cpu()\n",
    "original_batch=batch\n",
    "model.flow.train()\n",
    "model.dis_net.train()\n",
    "model.gen_net.train()\n",
    "model.data_module.scaler.to(\"cuda\")\n",
    "batch = original_batch[:50000].to(\"cuda\")\n",
    "model.flow = model.flow.to(\"cuda\")\n",
    "model.dis_net = model.dis_net.cuda()\n",
    "model.gen_net = model.gen_net.cuda()\n",
    "start=time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "#for some wierd reason its better with mask==None???\n",
    "    mask_test = model.sample_n(mask[:50000]).bool().cuda()\n",
    "    gen, true, z, fake_scaled, true_scaled, z_scaled = model.sampleandscale(batch, mask=mask_test,scale=True)\n",
    "print((time.time()-start)/50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4451942-8bbd-4270-9d58-accd079e1bb8",
   "metadata": {},
   "source": [
    "# Print table for paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd555d0-107c-4502-a1c7-8c7f0a4a05c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    w1m_           w1p_      w1efp_   pmm   pmp   pme     cov  \\\n",
      "model                                                                           \n",
      "VNF        $4.8 \\pm 0.2$  $2.5 \\pm 0.3$  $13 \\pm 1$  0.21  0.32  1.43  $0.56$   \n",
      "TF         $2.6 \\pm 0.1$  $4.3 \\pm 0.4$  $12 \\pm 1$  0.11  0.43  1.22  $0.49$   \n",
      "MP-MP      $0.6 \\pm 0.2$  $2.3 \\pm 0.3$   $2 \\pm 1$  0.20  0.30  1.00  $0.57$   \n",
      "MP_LFC-MP  $0.9 \\pm 0.3$  $2.2 \\pm 0.7$   $2 \\pm 1$  0.30  0.70  1.00  $0.56$   \n",
      "\n",
      "            fpndv      mmd parton      model  \n",
      "model                                         \n",
      "VNF        $5.60$  $0.071$      t        VNF  \n",
      "TF         $4.46$  $0.084$      t         TF  \n",
      "MP-MP      $0.37$  $0.071$      t      MP-MP  \n",
      "MP_LFC-MP  $0.93$  $0.073$      t  MP_LFC-MP  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26200/200639810.py:74: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  for col in print_table.drop(\"model\",1).columns:\n",
      "/tmp/ipykernel_26200/200639810.py:79: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  temp_index=temp[col].str.replace(\"$\",\"\").str.split(\"\\\\\").str[0].astype(float)\n",
      "/tmp/ipykernel_26200/200639810.py:81: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  temp.loc[mins,col]=\"$\\mathbf{\"+temp.loc[mins,col].astype(str).str.replace(\"$\",\"\")+\"}$\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multirow{7}{*}{Top Quark} & \n",
      "MP-MP & $\\mathbf{0.6 \\pm 0.2}$ &$2.3 \\pm 0.3$ &$\\mathbf{2 \\pm 1}$ & $\\mathbf{0.37}$ & $\\mathbf{0.57}$ & $\\mathbf{0.071}$ \\\\&\n",
      "\n",
      "MP\\_LFC-MP &$0.9 \\pm 0.3$ & $\\mathbf{2.2 \\pm 0.7}$ &$\\mathbf{2 \\pm 1}$ &$0.93$ &$0.56$ &$0.073$ \\\\&\n",
      "VNF &$4.8 \\pm 0.2$ &$2.5 \\pm 0.3$ &$13 \\pm 1$ &$5.60$ &$0.56$ & $\\mathbf{0.071}$ \\\\&\n",
      " TF &$2.6 \\pm 0.1$ &$4.3 \\pm 0.4$ &$12 \\pm 1$ &$4.46$ &$0.49$ &$0.084$ \\\\\\cline{1-8}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26200/200639810.py:84: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  text=temp.to_latex(index=False,escape=False)\n"
     ]
    }
   ],
   "source": [
    "def format_mean_sd(mean, sd):\n",
    "    \"\"\"round mean and standard deviation to most significant digit of sd and apply latex formatting\"\"\"\n",
    "    decimals = -int(np.floor(np.log10(sd)))\n",
    "    decimals -= int((sd * 10 ** decimals) >= 9.5)\n",
    "\n",
    "    if decimals < 0:\n",
    "        ten_to = 10 ** (-decimals)\n",
    "        if mean > ten_to:\n",
    "            mean = ten_to * (mean // ten_to)\n",
    "        else:\n",
    "            mean_ten_to = 10 ** np.floor(np.log10(mean))\n",
    "            mean = mean_ten_to * (mean // mean_ten_to)\n",
    "        sd = ten_to * (sd // ten_to)\n",
    "        decimals = 0\n",
    "\n",
    "    if mean >= 1e3 and sd >= 1e3:\n",
    "        mean = np.round(mean * 1e-3)\n",
    "        sd = np.round(sd * 1e-3)\n",
    "        return f\"${mean:.{decimals}f}$k $\\\\pm {sd:.{decimals}f}$k\"\n",
    "    else:\n",
    "        return f\"${mean:.{decimals}f} \\\\pm {sd:.{decimals}f}$\"\n",
    "\n",
    "# print_table.index=[\"t\"]#\"q\"\n",
    "# print_table[\"model\"]=[\"t\"]#\"q\"\n",
    "cols=[\"w1m_\",\"w1p_\",\"w1efp_\",\"pmm\",\"pmp\",\"pme\",\"cov\",\"fpndv\",\"mmd\",\"model\"]\n",
    "\n",
    "print_table=pd.DataFrame([[w1m_z[0],w1p_z[0],w1efp_z[0],w1m_z[1],w1p_z[1]\n",
    "                          ,w1efp_z[1],covz,fpndvz,mmdz,\"VNF\"],[w1m_[0],w1p_[0],w1efp_[0],w1m_[1],w1p_[1]\n",
    "                          ,w1efp_[1],cov,fpndv,mmd,\"TF\",]],columns=cols).set_index(\"model\",drop=False)\n",
    "\n",
    "\n",
    "print_table.loc[:,\"w1m_\"]*=1000\n",
    "print_table.loc[:,\"w1p_\"]*=1000\n",
    "print_table.loc[:,\"w1efp_\"]*=100000\n",
    "print_table.loc[:,\"pmm\"]*=1000\n",
    "print_table.loc[:,\"pmp\"]*=1000\n",
    "print_table.loc[:,\"pme\"]*=100000\n",
    "\n",
    "\n",
    "print_table.loc[\"MP-MP-t\",:]=np.array([0.6,2.3,2,.2,.3,1,0.57,0.37,0.071,\"MP-MP\"])\n",
    "print_table.loc[\"MPLFC-MP-t\",:]=np.array([0.9,2.2,2,.3,.7,1,0.56,0.93,0.073,\"MP_LFC-MP\"])\n",
    "print_table.loc[:,\"w1m_\"]=print_table.apply(lambda x:format_mean_sd(float(x[\"w1m_\"]),float(x[\"pmm\"])),axis=1)\n",
    "print_table.loc[:,\"w1efp_\"]=print_table.apply(lambda x:format_mean_sd(float(x[\"w1efp_\"]),float(x[\"pme\"])),axis=1)\n",
    "print_table.loc[:,\"w1p_\"]=print_table.apply(lambda x:format_mean_sd(float(x[\"w1p_\"]),float(x[\"pmp\"])),axis=1)\n",
    "\n",
    "\n",
    "print_table.loc[:,\"cov\"]=print_table.loc[:,\"cov\"].astype(float).map('{:.2f}'.format)\n",
    "print_table.loc[:,\"fpndv\"]=print_table.loc[:,\"fpndv\"].astype(float).map('{:.2f}'.format)\n",
    "print_table.loc[:,\"mmd\"]=print_table.loc[:,\"mmd\"].astype(float).map('{:.3f}'.format)\n",
    "print_table.loc[:,\"pmm\"]=print_table.loc[:,\"pmm\"].astype(float).map('{:,.2f}'.format)\n",
    "\n",
    "print_table.loc[:,\"pmp\"]=print_table.loc[:,\"pmp\"].astype(float).map('{:,.2f}'.format)\n",
    "\n",
    "print_table.loc[:,\"pme\"]=print_table.loc[:,\"pme\"].astype(float).map('{:,.2f}'.format)\n",
    "print_table.loc[:,\"parton\"]=\"t\"\n",
    "# print_table.loc[:,\"val_w1m\"]=\"$\"+print_table[\"val_w1m\"].map(str)+\"\\pm\"+print_table[\"pmm\"].map(str)+\"$\"\n",
    "# print_table.loc[:,\"val_w1p\"]=\"$\"+print_table[\"val_w1p\"].map(str)+\"\\pm\"+print_table[\"pmp\"].map(str)+\"$\"\n",
    "# print_table.loc[:,\"val_w1efp\"]=\"$\"+print_table[\"val_w1efp\"].map(str)+\"\\pm\"+print_table[\"pme\"].map(str)+\"$\"\n",
    "print_table.loc[:,\"cov\"]=\"$\"+print_table[\"cov\"].map(str)+\"$\"\n",
    "print_table.loc[:,\"fpndv\"]=\"$\"+print_table[\"fpndv\"].map(str)+\"$\"\n",
    "print_table.loc[:,\"mmd\"]=\"$\"+print_table[\"mmd\"].map(str)+\"$\"\n",
    "\n",
    "# print_table.loc[:,\"model\"]=print_table[\"model\"].str.replace(\"c0\",\"VNF\").str.replace(\"cc\",\"NFCC\").str.replace(\"c\",\"NFC\").str.replace(\"1\",\"\\ (m)\").str.replace(\"2\",\"\\ (m,n)\").str.replace(\"q\",\"\").str.replace(\"g\",\"\").str.replace(\"t\",\"\")\n",
    "index=[\"MP-MP\",\"MP_LFC-MP\",\"VNF\",\"TF\"]#\"MP-MP-q\",\"MPLFC-MP-q\",\"q\"\n",
    "print_table=print_table.set_index(\"model\")\n",
    "print_table[\"model\"]=print_table.index\n",
    "print(print_table)\n",
    "print_table=print_table.loc[index,:]\n",
    "final_table=pd.DataFrame()\n",
    "tex=\"\"\n",
    "for p in [\"t\"]:#\"q\",\n",
    "    temp=print_table[print_table[\"parton\"]==p]\n",
    "\n",
    "    for col in print_table.drop(\"model\",1).columns:\n",
    "        \n",
    "        if col not in [\"w1m_\",\"w1p_\",\"w1efp_\",\"fpndv\",\"cov\",\"mmd\" ]:\n",
    "            continue\n",
    "        \n",
    "        temp_index=temp[col].str.replace(\"$\",\"\").str.split(\"\\\\\").str[0].astype(float)\n",
    "        mins=temp_index==temp_index.min() if col!=\"cov\" else temp_index==temp_index.max()\n",
    "        temp.loc[mins,col]=\"$\\mathbf{\"+temp.loc[mins,col].astype(str).str.replace(\"$\",\"\")+\"}$\"\n",
    "    temp=temp[[\"model\",\"w1m_\",\"w1p_\",\"w1efp_\",\"fpndv\",\"cov\",\"mmd\"]]\n",
    "    temp.columns=[\"model\",\"$W_1^M (\\times 10^{-3})$\",\"$W_1^P (\\times 10^{-3})$\",\"$W_1^{EFP}(\\times 10^{-5})$\",\"FPND\",r\"COV $\\uparrow$\",\"MMD\"]\n",
    "    text=temp.to_latex(index=False,escape=False)\n",
    "    parton=\"Gluon\" if p==\"g\" else \"Light Quark\" if p==\"q\" else \"Top Quark\"\n",
    "    tex+=\"\\multirow{7}{*}{\"+parton+\"} & \"+text.split(\"MMD \\\\\\\\\")[1].split(\"\\\\bottomrule\")[0].replace(\"\\\\\\\\\",\"\\\\\\\\&\").replace(\"\\\\midrule\",\"\").replace(\"MP_LFC\",\"MP\\_LFC\").replace(\"  \",\"\")[:-2]+\"\\cline{1-8}\" \n",
    "    tex+=\"\\n\"\n",
    "print(tex)\n",
    "\n",
    "    #     final_table=final_table.append(temp)\n",
    "\n",
    "# print(final_table.to_latex(index=False,escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6ea3ec-5c98-4228-8a69-d1eb5c845a9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m m_c \u001b[38;5;241m=\u001b[39m mass(fake_scaled[:, : model\u001b[38;5;241m.\u001b[39mn_dim \u001b[38;5;241m*\u001b[39m model\u001b[38;5;241m.\u001b[39mn_part], model\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanonical\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      7\u001b[0m plot\u001b[38;5;241m=\u001b[39mplotting_paper(true_scaled,fake_scaled,config,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_mass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43mm_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mquantile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mplot_vline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mplotting_paper.plot_mass\u001b[0;34m(self, m, m_t, save, quantile, bins, plot_vline, title)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v,name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m],[\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124meta^\u001b[39m\u001b[38;5;132;01m{rel}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mphi^\u001b[39m\u001b[38;5;132;01m{rel}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$p_T^\u001b[39m\u001b[38;5;132;01m{rel}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$m^\u001b[39m\u001b[38;5;132;01m{rel}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 286\u001b[0m         a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m,np\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_set[:,i],\u001b[38;5;241m0.001\u001b[39m))\n\u001b[1;32m    287\u001b[0m         b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(np\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen[:,i],\u001b[38;5;241m0.999\u001b[39m),np\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_set[:,i],\u001b[38;5;241m0.999\u001b[39m))     \n\u001b[1;32m    289\u001b[0m         h\u001b[38;5;241m=\u001b[39mhist\u001b[38;5;241m.\u001b[39mHist(hist\u001b[38;5;241m.\u001b[39maxis\u001b[38;5;241m.\u001b[39mRegular(bins,a,b))\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mquantile\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/beegfs/desy/user/kaechben/.conda/envs/jetnet/lib/python3.8/site-packages/numpy/lib/function_base.py:3979\u001b[0m, in \u001b[0;36mquantile\u001b[0;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[1;32m   3977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[1;32m   3978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantiles must be in the range [0, 1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/beegfs/desy/user/kaechben/.conda/envs/jetnet/lib/python3.8/site-packages/numpy/lib/function_base.py:3986\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[1;32m   3983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a, q, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overwrite_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3984\u001b[0m                         interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3985\u001b[0m     \u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3986\u001b[0m     r, k \u001b[38;5;241m=\u001b[39m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3987\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3988\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3989\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m   3990\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mreshape(q\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m k)\n",
      "File \u001b[0;32m/beegfs/desy/user/kaechben/.conda/envs/jetnet/lib/python3.8/site-packages/numpy/lib/function_base.py:3539\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ureduce\u001b[39m(a, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3514\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3515\u001b[0m \u001b[38;5;124;03m    Internal Function.\u001b[39;00m\n\u001b[1;32m   3516\u001b[0m \u001b[38;5;124;03m    Call `func` with `a` as first argument swapping the axes to use extended\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3537\u001b[0m \n\u001b[1;32m   3538\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3539\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3540\u001b[0m     axis \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   3541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/beegfs/desy/user/kaechben/.conda/envs/jetnet/lib/python3.8/site-packages/torch/_tensor.py:732\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.font_manager:findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABXAAAAFtCAYAAACuiEL4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAngklEQVR4nO3df6il910n8PdnSUrapht/ZJK41ZhK1XHTxaG9MURarBuQVaEkCCmDLdZsTUEDCRSU/cdGdqEsLHJLorhjaVNLaXRxnQWxKyHYPxLtmhtJakxg6dI26jYz01p/TDrVNPnuH+cZezM7M/ecM+c853vOeb3g8NzzzPfkfj85hzeX9zn3udVaCwAAAAAA/fkXq94AAAAAAADnp8AFAAAAAOiUAhcAAAAAoFMKXAAAAACATilwAQAAAAA6pcAFAAAAAOiUAhcAAAAAoFNTFbhVdW9VfbaqXqqqVlX3HbD+iqq6v6pOVtWZqnqsqm5eyI4BNpzMBRiPzAUYl9wFmN20n8B9S5K/SfKXU67fTXJ3khNJjie5JcnDVXX1jPsD2EYyF2A8MhdgXHIXYEZTFbittXe31t6e5MmD1lbVNUnuTPJykltba0eTfCLJ6zIJXQAuQuYCjEfmAoxL7gLMbhnXwL0xyeVJnmutnRzO7Q3HI0v4fgDbTOYCjEfmAoxL7gIkuWwJ/81rh+PpfedeGI7Xne8BVXVXkruS5LWvfe1bDh8+vIRtAUzviSee+HJr7dCq9zEFmQusPZkLMJ41ytxE7gIbYBG5u4wC98RwvHLfubNfP3++B7TWjiU5liQ7Ozttb2/vfMsARlNVX1z1HqYkc4G1J3MBxrNGmZvIXWADLCJ3L/kSClV1VVUdrqobhlPPJHkxyfVVdfbdspuG41OX+v0AtpnMBRiPzAUYl9wFOL+pPoFbVe9N8tYkbx5O3TYE6vEk35Lko5mE55HW2omqejDJzyV5pKqeTnJHJr/y8MAC9w6wkWQuwHhkLsC45C7A7Ka9hMJbk/zMvvs/ONy+MNzOdU8m75LdkeSNST6T5P2ttVPzbhRgi8hcgPHIXIBxyV2AGVVrbdV7eAXXqAF6UFVPtNZ2Vr2PZZO5QA9kLsB4tiVzE7kL9GERuXvJ18AFAAAAAGA5FLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdGqqAreqrqiq+6vqZFWdqarHqurmi6w/UlV/WFVfqaqvVdUzVfXzi9s2wOaSuQDjkrsA45G5ALOb9hO4u0nuTnIiyfEktyR5uKquvsD640l+LMn/SfK7SQ4n+bWq+tFL2CvAttiNzAUY027kLsBYdiNzAWZyYIFbVdckuTPJy0luba0dTfKJJK/LJHTPXX95ku8a7t7ZWnt3kj8b7t+wgD0DbCyZCzAuuQswHpkLMJ9pPoF7Y5LLkzzXWjs5nNsbjkfOXdxaezHJh4a7H6mqjyd5c5Knkvze+b5BVd1VVXtVtXfq1KkZtg+wcWQuwLiWmrsyF+AV/KwLMIdpCtxrh+PpfedeGI7XXeAxx5N8IclNSd6V5BvDuX843+LW2rHW2k5rbefQoUNTbAlgY8lcgHEtNXdlLsAr+FkXYA7TFLgnhuOV+86d/fr5cxdX1bcn+VQmv87wtiTfluTJJB9I8r459wmwLWQuwLjkLsB4ZC7AHKYpcJ9J8mKS66vq7LtlNw3Hp6rqqqo6XFU3DOfekOQ1w2Meb619Ncmzw7/9wGK2DbCxZC7AuOQuwHhkLsAcDixwW2snkjw4rH2kqh5KcjSTX3l4IMntmQTo8eEhzyb5m0yua/NIVX1sWJ8kjy5w7wAbR+YCjEvuAoxH5gLM57Ip192TyTtedyR5Y5LPJHl/a+1UVb1iYWvthar6iST/KZOLi785yeeS/NfW2m8vauMAG0zmAoxL7gKMR+YCzKhaa6vewyvs7Oy0vb29gxcCLFFVPdFa21n1PpZN5gI9kLkA49mWzE3kLtCHReTuNNfABQAAAABgBRS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdmqrAraorqur+qjpZVWeq6rGquvmAx9xeVY8P6/+uqh6tqm9dzLYBNpfMBRiX3AUYj8wFmN20n8DdTXJ3khNJjie5JcnDVXX1+RZX1dEk/z3Jv0nyP5L8tyT/MslrLm27AFthNzIXYEy7kbsAY9mNzAWYyWUHLaiqa5LcmeTlJLe21k5W1TeSvCuT0L3vnPWV5D8Pd/9da+3Ti9wwwCaTuQDjkrsA45G5APOZ5hO4Nya5PMlzrbWTw7m94XjkPOu/N8l3JTmT5Ber6nRVfa6qfuFSNwuwBWQuwLjkLsB4ZC7AHKYpcK8djqf3nXthOF53nvVnf+3h1Um+J8nvJHl9kgeq6rbzfYOququq9qpq79SpU1NsCWBjyVyAcS01d2UuwCv4WRdgDtMUuCeG45X7zp39+vnzrN+fkO9urd2Z5CPD/Xec7xu01o611nZaazuHDh2aYksAG0vmAoxrqbkrcwFewc+6AHOYpsB9JsmLSa6vqrPvlt00HJ+qqquq6nBV3TCc+2KSv7/Af+v0Bc4DMCFzAcYldwHGI3MB5nBggdtaO5HkwWHtI1X1UJKjmYTlA0luT/JsJn89Mq21f8rkr0omyW9V1UcyuUj5S0k+sdDdA2wYmQswLrkLMB6ZCzCfy6Zcd08m75LdkeSNST6T5P2ttVOTPwr5//mPSV6V5D1J3pnk6SQfaK39r0vdMMAWkLkA45K7AOORuQAzqtbaqvfwCjs7O21vb+/ghQBLVFVPtNZ2Vr2PZZO5QA9kLsB4tiVzE7kL9GERuTvNNXABAAAAAFgBBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnZqqwK2qK6rq/qo6WVVnquqxqrp5iscdrao23HYvebcAW0DmAoxL7gKMR+YCzG7aT+DuJrk7yYkkx5PckuThqrr6Qg+oqu9M8utJvnFpWwTYOruRuQBj2o3cBRjLbmQuwEwOLHCr6pokdyZ5OcmtrbWjST6R5HWZhO75HlNJPpbk/yb53YXtFmDDyVyAccldgPHIXID5TPMJ3BuTXJ7kudbayeHc3nA8coHH3JvkrUl+OsnXD/oGVXVXVe1V1d6pU6em2BLAxpK5AONaau7KXIBX8LMuwBymKXCvHY6n9517YThed+7iqnpTkg8m+eXW2pPTbKK1dqy1ttNa2zl06NA0DwHYVDIXYFxLzV2ZC/AKftYFmMNlU6w5MRyv3Hfu7NfPn2f9TyV5VZIfqaq3JfnB4fw7qupMa+0/zLVTgO0gcwHGJXcBxiNzAeYwTYH7TJIXk1xfVde21k4kuWn4t6eq6qok35Hk6621LySp4fbj5/x33pDJxckBuDCZCzAuuQswHpkLMIcDL6EwBOqDw9pHquqhJEcz+ZWHB5LcnuTZTP56ZFpr97XW6uwtk4uNJ8mHWmtvX/QAAJtE5gKMS+4CjEfmAsxnmk/gJsk9mbxLdkeSNyb5TJL3t9ZOTf4gJAALJHMBxiV3AcYjcwFmVK21Ve/hFXZ2dtre3t7BCwGWqKqeaK3trHofyyZzgR7IXIDxbEvmJnIX6MMicvfASygAAAAAALAaClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTClwAAAAAgE5NVeBW1RVVdX9VnayqM1X1WFXdfJH1H66qZ6vqdFV9par+oKretLhtA2wumQswLrkLMB6ZCzC7aT+Bu5vk7iQnkhxPckuSh6vq6gus//dJ/jbJJ5P8fZIfT/I/q+qKS9grwLbYjcwFGNNu5C7AWHYjcwFmctlBC6rqmiR3Jnk5ya2ttZNV9Y0k78okdO87z8N2WmtPDI+/Icnnk7w+yb9O8mcL2TnABpK5AOOSuwDjkbkA85nmE7g3Jrk8yXOttZPDub3heOR8DzgbroNXDceXknxpjj0CbBOZCzAuuQswHpkLMIdpCtxrh+PpfedeGI7XXeyBVXVlko8Od3+1tXbegK2qu6pqr6r2Tp06NcWWADaWzAUY11JzV+YCvIKfdQHmME2Be2I4Xrnv3Nmvn7/Qg6rqUJI/SvLDSX4zyS9daG1r7Vhrbae1tnPo0KEptgSwsWQuwLiWmrsyF+AV/KwLMIdpCtxnkryY5PqqOvtu2U3D8amquqqqDg/XokmSVNV3J3k0yU6SD7bW7mqttQXuG2BTyVyAccldgPHIXIA5HFjgttZOJHlwWPtIVT2U5Ggmv/LwQJLbkzybyV+PPOuPk3xfkueSvKaqdofbDy109wAbRuYCjEvuAoxH5gLM57Ip192TybtkdyR5Y5LPJHl/a+1UVZ1v/b8ajtcPjz3rySR/OtdOAbaHzAUYl9wFGI/MBZhR9fabBzs7O21vb+/ghQBLVFVPtNZ2Vr2PZZO5QA9kLsB4tiVzE7kL9GERuTvNNXABAAAAAFgBBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnVLgAgAAAAB0SoELAAAAANApBS4AAAAAQKcUuAAAAAAAnZqqwK2qK6rq/qo6WVVnquqxqrp5UesB+CaZCzAuuQswHpkLMLtpP4G7m+TuJCeSHE9yS5KHq+rqBa0H4Jt2I3MBxrQbuQswlt3IXICZHFjgVtU1Se5M8nKSW1trR5N8IsnrMgnRS1oPwDfJXIBxyV2A8chcgPlcNsWaG5NcnuQLrbWTw7m9JO9KcmQB61NVdyW5a7j7j1X19DSbX3NXJ/nyqjcxAnNulm2ZM0m+f0XfV+Yux7a8drdlzmR7Zt2WOVeVucmSc3dLMzfZnteuOTfLtsy5sZmbbG3ubstr15ybZ1tmveTcnabAvXY4nt537oXheN0C1qe1dizJsSSpqr3W2s4U+1pr5tws5tw8VbW3om8tc5fAnJtnW2bdpjlX+O2XmrvbmLnJ9sxqzs2yTXOu8Nv7WXcJzLlZtmXOZHtmXUTuTnMN3BPD8cp9585+/fwC1gPwTTIXYFxyF2A8MhdgDtMUuM8keTHJ9VV19t2vm4bjU1V1VVUdrqobplm/gD0DbDKZCzAuuQswHpkLMIcDC9zW2okkDw5rH6mqh5IczeRXGB5IcnuSZzP5a5DTrD/IsRlnWFfm3Czm3DwrmVXmLo05N8+2zGrOJRs5d7fl+Uy2Z1ZzbhZzLpmfdZfGnJtlW+ZMtmfWS56zWmsHL6p6dZL/kuSOTP7a458leX9r7U+q6j1JPprkqdbakYPWX+qGATadzAUYl9wFGI/MBZjdVAUuAAAAAADjm+YauAAAAAAArIACFwAAAACgU6MWuFV1RVXdX1Unq+pMVT1WVTcvan0v5pjzw1X1bFWdrqqvVNUfVNWbxtzzPOZ9fqrqaFW14bY7wlYvyTxzVtXtVfX4sP7vqurRqvrWsfY8jzlet0eq6g+H1+zXquqZqvr5Mfc8j6q6t6o+W1UvDa/B+w5Yv5Y5lMjci6yXuZ2TuxdcL3c7JnMvuH4tMzfZntyVuRdcL3M7J3cvuH4tc1fmXvQxMrdTo2Zua220W5LfSNKS/HmSTyZ5OcnfJ7l6Eet7uc0xZ0vyJ0l+M8nnh/t/leSKVc+yyDmHx3xnkq8meXF47O6q51jC83l0WP/1JA8l+XCSzyZ5/apnWfCcXxjW/2mSjw/rW5IfXfUsB8z58SSf3rf/+xb5/6Wnm8yVueuYuXM+p3K3g3kuMudW5K7M3azMnfc5Wsfclbkydx2zaM7ndC1n3ZbclbkyV+Ye8L1GHOqaJP+U5KUk1+wb9LwDzrq+l9s8+07yln1f3zCsbUnevOp5FjxnJXkkyV8MwdN9wM7xuq0kzw3//vZV73+Jc14+rG1J3jSc2xvu/+yq55ly5uMH5cm65tCcz+lazipzNytz55lV7srdHm4yd7My9xJmXbvclbkydx2zaM7ndC1n3ZbclbkyV+YenENjXkLhxuFJea61dnI4tzccjyxgfS9m3ndr7Yl9d181HF9K8qVlbHBB5nl+7k3y1iQ/ncm7R+tg1jm/N8l3JTmT5BeHX1v5XFX9wtJ3emlmmrO19mKSDw13P1JVH0/y5iRPJfm95W51VOuaQ4nMTWTuvVm/zE3kbiJ3tyGLtmXOdc3cZHtyV+bK3HXMokTuJpuVuzJX5srcA4xZ4F47HE/vO/fCcLxuAet7Mfe+q+rKJB8d7v5qa63ngJ1pzuGaOx9M8suttSeXu7WFmvX5vHo4vjrJ9yT5nSSvT/JAVd22jA0uyDyv2+OZ/JrATUneleQbw7l/WPjuVmddcyiRuYnMXcfMTeRuIneTzc+ibZnzn61Z5ibbk7syV+Ym65dFidxNNit3Za7MPR6Ze1FjFrgnhuOV+86d/fr5BazvxVz7rqpDSf4oyQ9ncq2aX1rK7hZn1jl/KpN3/36kqn4/ya3D+XdU1QeXs8WFmHXOU/u+fndr7c4kHxnuv2PBe1ukmeasqm9P8qlMfiXnbUm+LcmTST6Q5H3L2uQKrGsOJTI3kbnrmLmJ3E3kbrL5WbQtcyZZy8xNtid3Za7MTdYvixK5m2xW7spcmStzDzBmgftMJheWvr6qzrbONw3Hp6rqqqo6XFU3TLN+jA3PadY5U1XfneTRJDtJPthau6sNF8Po2Kxz1nD78SQ/mcnFxpPkDUluGWfLc5l1zi9mcgHq8zl9gfM9mHXONyR5zfCYx1trX03y7PBvPzDSnhdug3IokbmJzF3HzE3kbiJ3tyGLtmXOdc3cZHtyV+bK3HXMokTuJpuVuzJX5srcg4x8Ud9jmVyc9+lMLjL9ciYfhz6U5D3Dvz05zfox9z3CnH89nPtikt19tx9a9SyLnPOcxz6YNbjI+JzP568M557N5N2xM5l8/P/mVc+yqDmTvDbJV4Zzjyb5WCYX425J3rnqWQ6Y873D6+/sxeCfHO7ftkk5NOdrdy1nlbmblblzPqdyt4N5LjLnVuSuzN2szJ1n1nMeuza5K3Nl7jpm0Zyv3bWcdVtyV+bKXJl7wPcaebBXJ/m1TD4G/vUkf5zkluHfzjfYBdf3fJtjznaB23tWPcsi5zznsesUsLM+n5dlcj2eL2VyPZPHk/zEqudYwpw3J3l4CNqvZfJu0j2rnmOKOc++9s693bdJOTTnc7qWs8rczcrcOZ9TudvxbVtyV+ZuVubOM+s5j12b3JW5Mncds2jO53QtZ92W3JW5MlfmXvxWw38AAAAAAIDOjHkNXAAAAAAAZqDABQAAAADolAIXAAAAAKBTClwAAAAAgE4pcAEAAAAAOqXABQAAAADolAIXAAAAAKBTUxW4VXVvVX22ql6qqlZV9x2w/oqqur+qTlbVmap6rKpuXsiOATaczAUYj8wFGJfcBZjdtJ/AfUuSv0nyl1Ou301yd5ITSY4nuSXJw1V19Yz7A9hGMhdgPDIXYFxyF2BGUxW4rbV3t9benuTJg9ZW1TVJ7kzycpJbW2tHk3wiyesyCV0ALkLmAoxH5gKMS+4CzG4Z18C9McnlSZ5rrZ0czu0NxyNL+H4A20zmAoxH5gKMS+4CJLlsCf/Na4fj6X3nXhiO153vAVV1V5K7kuS1r33tWw4fPryEbQFM74knnvhya+3QqvcxBZkLrD2ZCzCeNcrcRO4CG2ARubuMAvfEcLxy37mzXz9/vge01o4lOZYkOzs7bW9v73zLAEZTVV9c9R6mJHOBtSdzAcazRpmbyF1gAywidy/5EgpVdVVVHa6qG4ZTzyR5Mcn1VXX23bKbhuNTl/r9ALaZzAUYj8wFGJfcBTi/qT6BW1XvTfLWJG8eTt02BOrxJN+S5KOZhOeR1tqJqnowyc8leaSqnk5yRya/8vDAAvcOsJFkLsB4ZC7AuOQuwOymvYTCW5P8zL77PzjcvjDcznVPJu+S3ZHkjUk+k+T9rbVT824UYIvIXIDxyFyAccldgBlVa23Ve3gF16gBelBVT7TWdla9j2WTuUAPZC7AeLYlcxO5C/RhEbl7ydfABQAAAABgORS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRKgQsAAAAA0CkFLgAAAABApxS4AAAAAACdUuACAAAAAHRqqgK3qq6oqvur6mRVnamqx6rq5ous/3RVtXNuTy9u2wCbS+YCjEvuAoxH5gLM7rIp1+0meV+Sp5M8kuSdSR6uqu9prX35Io/70L6vvzTXDgG2z25kLsCYdiN3AcayG5kLMJMDC9yquibJnUleTnJra+1kVX0jybuS3J3kvgs9trV272K2CbAdZC7AuOQuwHhkLsB8prmEwo1JLk/yXGvt5HBubzgeudgDq+qrVfW3VfVIVd00/zYBtobMBRiX3AUYj8wFmMM0Be61w/H0vnMvDMfrLvCYf0jy+0l+O8kXk/zbJH9YVeddX1V3VdVeVe2dOnVqii0BbCyZCzCupeauzAV4BT/rAsxhmmvgnhiOV+47d/br5y/wmHe01lqSVNWrkvzvJN+d5EeTfPLcxa21Y0mOJcnOzk6bYk8Am0rmAoxrqbkrcwFewc+6AHOY5hO4zyR5Mcn1VXX23bKzv67wVFVdVVWHq+qGJKmq1yT5jgv8t16+lM0CbAGZCzAuuQswHpkLMIcDC9zW2okkDw5rH6mqh5IczeRXHh5IcnuSZ5McHx5yTZLPV9Wnquo3kjyeybtjJzL5C5MAXIDMBRiX3AUYj8wFmM80n8BNknuS/Hom16u5LclnkvxYa+18F5T5SpLfSvJ9SX5meMzxTP7C5Jcvcb8A20DmAoxL7gKMR+YCzKiGS8l0Y2dnp+3t7R28EGCJquqJ1trOqvexbDIX6IHMBRjPtmRuIneBPiwid6f9BC4AAAAAACNT4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQqakK3Kq6oqrur6qTVXWmqh6rqpsXtR6Ab5K5AOOSuwDjkbkAs5v2E7i7Se5OciLJ8SS3JHm4qq5e0HoAvmk3MhdgTLuRuwBj2Y3MBZjJgQVuVV2T5M4kLye5tbV2NMknkrwukxC9pPUAfJPMBRiX3AUYj8wFmM80n8C9McnlSZ5rrZ0czu0NxyMLWA/AN8lcgHHJXYDxyFyAOVw2xZprh+PpfedeGI7XLWB9ququJHcNd/+xqp6eYl/r7uokX171JkZgzs2yLXMmyfev6PvK3OXYltfutsyZbM+s2zLnqjI3WXLubmnmJtvz2jXnZtmWOTc2c5Otzd1tee2ac/Nsy6yXnLvTFLgnhuOV+86d/fr5BaxPa+1YkmNJUlV7rbWdKfa11sy5Wcy5eapq7+BVSyFzl8Ccm2dbZt2mOVf47Zeau9uYucn2zGrOzbJNc67w2/tZdwnMuVm2Zc5ke2ZdRO5OcwmFZ5K8mOT6qjr77tdNw/Gpqrqqqg5X1Q3TrL/UDQNsOJkLMC65CzAemQswhwML3NbaiSQPDmsfqaqHkhzN5FcYHkhye5JnM/lrkNOsB+ACZC7AuOQuwHhkLsB8prmEQpLck8m7XnckeWOSzyR5f2vtVFXNtH6K73Vsyj2tO3NuFnNunlXOKnMXz5ybZ1tmNec4xsrdVc85pm2Z1ZybxZzj8LPu4plzs2zLnMn2zHrJc1ZrbREbAQAAAABgwaa5Bi4AAAAAACugwAUAAAAA6NSoBW5VXVFV91fVyao6U1WPVdXNi1rfiznm/HBVPVtVp6vqK1X1B1X1pjH3PI95n5+qOlpVbbjtjrDVSzLPnFV1e1U9Pqz/u6p6tKq+daw9z2OO1+2RqvrD4TX7tap6pqp+fsw9z6Oq7q2qz1bVS8Nr8L4D1q9lDiUy9yLrZW7n5O4F18vdjsncC65fy8xNtid3Ze4F18vczsndC65fy9yVuRd9jMzt1KiZ21ob7ZbkN5K0JH+e5JNJXk7y90muXsT6Xm5zzNmS/EmS30zy+eH+XyW5YtWzLHLO4THfmeSrmVyEviXZXfUcS3g+jw7rv57koSQfTvLZJK9f9SwLnvMLw/o/TfLxYX1L8qOrnuWAOT+e5NP79n/fIv+/9HSTuTJ3HTN3zudU7nYwz0Xm3IrclbmblbnzPkfrmLsyV+auYxbN+Zyu5azbkrsyV+bK3AO+14hDXZPkn5K8lOSafYOed8BZ1/dym2ffSd6y7+sbhrUtyZtXPc+C56wkjyT5iyF4ug/YOV63leS54d/fvur9L3HOy4e1LcmbhnN7w/2fXfU8U858/KA8WdccmvM5XctZZe5mZe48s8pdudvDTeZuVuZewqxrl7syV+auYxbN+Zyu5azbkrsyV+bK3INzaMxLKNw4PCnPtdZODuf2huORBazvxcz7bq09se/uq4bjS0m+tIwNLsg8z8+9Sd6a5KczefdoHcw65/cm+a4kZ5L84vBrK5+rql9Y+k4vzUxzttZeTPKh4e5HqurjSd6c5Kkkv7fcrY5qXXMokbmJzL0365e5idxN5O42ZNG2zLmumZtsT+7KXJm7jlmUyN1ks3JX5spcmXuAMQvca4fj6X3nXhiO1y1gfS/m3ndVXZnko8PdX22t9RywM805XHPng0l+ubX25HK3tlCzPp9XD8dXJ/meJL+T5PVJHqiq25axwQWZ53V7PJNfE7gpybuSfGM49w8L393qrGsOJTI3kbnrmLmJ3E3kbrL5WbQtc/6zNcvcZHtyV+bK3GT9siiRu8lm5a7MlbnHI3MvaswC98RwvHLfubNfP7+A9b2Ya99VdSjJHyX54UyuVfNLS9nd4sw6509l8u7fj1TV7ye5dTj/jqr64HK2uBCzznlq39fvbq3dmeQjw/13LHhvizTTnFX17Uk+lcmv5LwtybcleTLJB5K8b1mbXIF1zaFE5iYydx0zN5G7idxNNj+LtmXOJGuZucn25K7MlbnJ+mVRIneTzcpdmStzZe4Bxixwn8nkwtLXV9XZ1vmm4fhUVV1VVYer6oZp1o+x4TnNOmeq6ruTPJpkJ8kHW2t3teFiGB2bdc4abj+e5Cczudh4krwhyS3jbHkus875xUwuQH0+py9wvgezzvmGJK8ZHvN4a+2rSZ4d/u0HRtrzwm1QDiUyN5G565i5idxN5O42ZNG2zLmumZtsT+7KXJm7jlmUyN1ks3JX5spcmXuQkS/qeyyTi/M+nclFpl/O5OPQh5K8Z/i3J6dZP+a+R5jzr4dzX0yyu+/2Q6ueZZFznvPYB7MGFxmf8/n8leHcs5m8O3Ymk4//37zqWRY1Z5LXJvnKcO7RJB/L5GLcLck7Vz3LAXO+d3j9nb0Y/JPD/ds2KYfmfO2u5awyd7Myd87nVO52MM9F5tyK3JW5m5W588x6zmPXJndlrsxdxyya87W7lrNuS+7KXJkrcw/4XiMP9uokv5bJx8C/nuSPk9wy/Nv5Brvg+p5vc8zZLnB7z6pnWeSc5zx2nQJ21ufzskyux/OlTK5n8niSn1j1HEuY8+YkDw9B+7VM3k26Z9VzTDHn2dfeubf7NimH5nxO13JWmbtZmTvncyp3O75tS+7K3M3K3HlmPeexa5O7MlfmrmMWzfmcruWs25K7MlfmytyL32r4DwAAAAAA0Jkxr4ELAAAAAMAMFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECnFLgAAAAAAJ1S4AIAAAAAdEqBCwAAAADQKQUuAAAAAECn/h/TIxgogoLafgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1728x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_t = mass(\n",
    "        true_scaled[:, : model.n_dim * model.n_part].to(model.device),\n",
    "        model.config[\"canonical\"],\n",
    "    ).cpu()\n",
    "m_gen = mass(z_scaled[:, : model.n_dim * model.n_part], model.config[\"canonical\"]).cpu()\n",
    "m_c = mass(fake_scaled[:, : model.n_dim * model.n_part], model.config[\"canonical\"]).cpu()\n",
    "plot=plotting_paper(true_scaled,fake_scaled,config,0,\"t\",model=model)\n",
    "plot.plot_mass(m_c,m_t,save=False,quantile=False,bins=50,plot_vline=False,title=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43b88a6f-5acd-43b8-a738-394dc709acdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(30,30))-torch.diag(torch.ones(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f4fbd-daae-4697-a5ab-25140eca95c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetnet",
   "language": "python",
   "name": "jetnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
